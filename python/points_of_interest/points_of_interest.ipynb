{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as wid\n",
    "from utils.ipywidgets_extended import (\n",
    "    widgets_styling,\n",
    "    widgets_styling_slider,\n",
    "    MultiSelect,\n",
    "    RadioSelect,\n",
    ")\n",
    "\n",
    "from utils.setup_notebook import init_notebook\n",
    "from utils.setup_logging import setup_logging\n",
    "import utils.memoize as memoize\n",
    "\n",
    "init_notebook()\n",
    "setup_logging(\"INFO\")\n",
    "memoize.set_file_store_path(\"points_of_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numba as nb\n",
    "from numba import cuda\n",
    "import cv2\n",
    "\n",
    "from utils.benchmarking import LogTimer\n",
    "from utils.plotting_tools import (\n",
    "    SmartFigure,\n",
    "    to_ipy_image,\n",
    "    plot_kernel,\n",
    "    plot_matrix,\n",
    ")\n",
    "from utils.image_tools import load_image, LoadedImage, save_image\n",
    "import utils.dyn_module as dyn\n",
    "from utils.cv2_tools import draw_keypoints, draw_matches\n",
    "from utils.distinct_colors import bgrs\n",
    "\n",
    "logging.getLogger(\"numba.cuda.cudadrv.driver\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795fd07a67184bfa97f374c806c15762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset memoize store', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset_memoize_store_button = wid.Button(description=\"Reset memoize store\")\n",
    "reset_memoize_store_button.on_click(lambda x: memoize.reset_store())\n",
    "display(reset_memoize_store_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Points of Interest Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-29 13:22:10.790 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 1 modules \u001b[0mstarted \u001b[90m(../utils/dyn_module.py:59)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.796 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading harris_points_of_interest \u001b[0mstarted \u001b[90m(../utils/dyn_module.py:32)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.808 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading harris_points_of_interest \u001b[0mtook: \u001b[34m10.5187 ms\u001b[0m \u001b[90m(../utils/dyn_module.py:32)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.814 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 1 modules \u001b[0mtook: \u001b[34m73.4706 ms\u001b[0m \u001b[90m(../utils/dyn_module.py:59)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dir_points_of_interest_impls = \"./points_of_interest_impls\"\n",
    "points_of_interest_impls_module_names = dyn.load_modules(dir_points_of_interest_impls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Input Image Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-29 13:22:10.854 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_input \u001b[0mstarted \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.871 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.882 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.952 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam.jpg \u001b[0mtook: \u001b[34m65.6082 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:10.974 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.072 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back.tiff \u001b[0mtook: \u001b[34m78.8433 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.126 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.218 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front.tiff \u001b[0mtook: \u001b[34m118.8234 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.238 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.312 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back.tiff \u001b[0mtook: \u001b[34m82.5265 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.323 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.395 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front.tiff \u001b[0mtook: \u001b[34m70.9589 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.414 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.529 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera.jpg \u001b[0mtook: \u001b[34m113.0097 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.539 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.580 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner.tiff \u001b[0mtook: \u001b[34m40.0162 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.592 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.627 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front.tiff \u001b[0mtook: \u001b[34m34.4181 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.635 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.703 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera.jpg \u001b[0mtook: \u001b[34m65.6875 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.710 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.868 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera.jpg \u001b[0mtook: \u001b[34m152.7225 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.877 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.946 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner.tiff \u001b[0mtook: \u001b[34m64.7063 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:11.955 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.021 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front.tiff \u001b[0mtook: \u001b[34m64.7436 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.028 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.092 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back.tiff \u001b[0mtook: \u001b[34m60.8125 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.108 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front.tiff \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.190 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front.tiff \u001b[0mtook: \u001b[34m86.9997 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.198 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.490 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1.jpg \u001b[0mtook: \u001b[34m280.1431 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.506 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.833 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2.jpg \u001b[0mtook: \u001b[34m329.7635 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:12.846 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.124 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3.jpg \u001b[0mtook: \u001b[34m279.9055 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.132 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.404 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4.jpg \u001b[0mtook: \u001b[34m270.2479 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.416 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.702 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5.jpg \u001b[0mtook: \u001b[34m284.4259 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.713 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:13.995 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6.jpg \u001b[0mtook: \u001b[34m282.0999 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.008 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.283 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7.jpg \u001b[0mtook: \u001b[34m277.4855 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.292 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets \u001b[0mtook: \u001b[31m3.4278 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.299 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.307 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.654 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827.jpg \u001b[0mtook: \u001b[34m344.2896 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:14.667 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.120 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828.jpg \u001b[0mtook: \u001b[34m453.9361 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.131 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.496 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831.jpg \u001b[0mtook: \u001b[34m364.7057 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.506 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.839 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833.jpg \u001b[0mtook: \u001b[34m330.5597 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:15.848 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.217 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835.jpg \u001b[0mtook: \u001b[34m366.4386 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.229 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office \u001b[0mtook: \u001b[31m1.9274 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.240 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_room \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.252 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_224636.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.652 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_224636.jpg \u001b[0mtook: \u001b[34m397.3653 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:16.669 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_224640.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.076 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_224640.jpg \u001b[0mtook: \u001b[34m413.2992 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.085 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234400.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.462 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234400.jpg \u001b[0mtook: \u001b[34m375.6884 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.474 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234404.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.872 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234404.jpg \u001b[0mtook: \u001b[34m397.5134 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:17.885 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234407.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.254 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234407.jpg \u001b[0mtook: \u001b[34m370.9918 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.270 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234410.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.637 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234410.jpg \u001b[0mtook: \u001b[34m368.9895 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.645 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234413.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.984 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234413.jpg \u001b[0mtook: \u001b[34m336.9022 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:18.993 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234415.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:19.331 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234415.jpg \u001b[0mtook: \u001b[34m337.4726 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:19.340 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234417.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:19.690 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234417.jpg \u001b[0mtook: \u001b[34m349.1404 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:19.702 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234419.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.046 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234419.jpg \u001b[0mtook: \u001b[34m342.6370 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.054 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234421.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.410 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234421.jpg \u001b[0mtook: \u001b[34m352.8485 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.418 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234423.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.769 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234423.jpg \u001b[0mtook: \u001b[34m350.0801 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:20.778 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234424.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.165 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234424.jpg \u001b[0mtook: \u001b[34m384.1197 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.176 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234426.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.556 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234426.jpg \u001b[0mtook: \u001b[34m378.5606 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.566 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234428.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.969 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234428.jpg \u001b[0mtook: \u001b[34m402.8208 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:21.979 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234429.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:22.356 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234429.jpg \u001b[0mtook: \u001b[34m376.0955 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:22.364 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234431.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:22.706 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234431.jpg \u001b[0mtook: \u001b[34m339.1197 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:22.715 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234434.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.073 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234434.jpg \u001b[0mtook: \u001b[34m356.5075 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.084 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234436.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.463 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234436.jpg \u001b[0mtook: \u001b[34m376.2638 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.472 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234437.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.894 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234437.jpg \u001b[0mtook: \u001b[34m419.9069 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:23.902 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234439.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:24.354 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234439.jpg \u001b[0mtook: \u001b[34m446.6138 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:24.364 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234441.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:24.834 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234441.jpg \u001b[0mtook: \u001b[34m468.8938 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:24.842 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234443.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:25.316 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234443.jpg \u001b[0mtook: \u001b[34m471.1104 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:25.328 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234445.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:25.816 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234445.jpg \u001b[0mtook: \u001b[34m486.4219 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:25.824 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234447.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:26.245 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234447.jpg \u001b[0mtook: \u001b[34m417.2636 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:26.255 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234448.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:26.745 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234448.jpg \u001b[0mtook: \u001b[34m488.1918 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:26.757 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234450.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.213 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234450.jpg \u001b[0mtook: \u001b[34m454.2827 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.224 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234453.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.600 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234453.jpg \u001b[0mtook: \u001b[34m375.0421 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.608 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234456.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.964 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234456.jpg \u001b[0mtook: \u001b[34m354.0519 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:27.972 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234457.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:28.331 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234457.jpg \u001b[0mtook: \u001b[34m356.0843 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:28.340 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234459.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:28.683 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234459.jpg \u001b[0mtook: \u001b[34m342.1850 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:28.691 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234502.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.078 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234502.jpg \u001b[0mtook: \u001b[34m383.2102 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.087 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234504.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.450 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234504.jpg \u001b[0mtook: \u001b[34m361.8015 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.459 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234506.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.830 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234506.jpg \u001b[0mtook: \u001b[34m368.4423 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:29.840 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234508.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.203 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234508.jpg \u001b[0mtook: \u001b[34m360.4655 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.211 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234510.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.578 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234510.jpg \u001b[0mtook: \u001b[34m364.9051 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.587 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234513.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.954 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234513.jpg \u001b[0mtook: \u001b[34m364.9667 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:30.963 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234514.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:31.317 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234514.jpg \u001b[0mtook: \u001b[34m352.4969 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:31.326 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234517.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:31.680 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234517.jpg \u001b[0mtook: \u001b[34m352.7305 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:31.690 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234519.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.081 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234519.jpg \u001b[0mtook: \u001b[34m386.8365 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.091 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234521.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.474 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234521.jpg \u001b[0mtook: \u001b[34m381.5078 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.482 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234523.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.843 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234523.jpg \u001b[0mtook: \u001b[34m359.2619 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:32.854 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234525.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.208 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234525.jpg \u001b[0mtook: \u001b[34m353.6456 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.217 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234527.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.574 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234527.jpg \u001b[0mtook: \u001b[34m355.3882 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.584 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234529.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.946 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234529.jpg \u001b[0mtook: \u001b[34m359.5706 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:33.954 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234531.jpg \u001b[0mstarted \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:34.315 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241112_234531.jpg \u001b[0mtook: \u001b[34m357.9985 ms\u001b[0m \u001b[90m(../utils/image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:34.326 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_room \u001b[0mtook: \u001b[31m18.0875 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:34.338 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_input \u001b[0mtook: \u001b[31m23.4922 s\u001b[0m \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:34.353 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_scaled_input \u001b[0mstarted \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-29 13:22:34.360 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_scaled_input \u001b[0mtook: \u001b[34m8.5726 ms\u001b[0m \u001b[90m(notebook_cell:14)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_image_set_dir = \"./image_sets_input\"\n",
    "input_image_set_scaled_dir = \"./image_sets_scaled_input\"\n",
    "\n",
    "os.makedirs(input_image_set_dir, exist_ok=True)\n",
    "os.makedirs(input_image_set_scaled_dir, exist_ok=True)\n",
    "\n",
    "input_image_sets = {}\n",
    "\n",
    "\n",
    "def load_image_sets(image_sets_dir: str):\n",
    "    image_sets_folders = os.listdir(image_sets_dir)\n",
    "    image_sets_folders.sort()\n",
    "\n",
    "    with LogTimer(f\"Loading image sets from {Path(image_sets_dir).name}\"):\n",
    "        for image_set_name in image_sets_folders:\n",
    "            with LogTimer(f\"Loading image set {image_set_name}\"):\n",
    "                image_set_dir = os.path.join(image_sets_dir, image_set_name)\n",
    "                image_set = []\n",
    "\n",
    "                images_in_image_set = os.listdir(image_set_dir)\n",
    "                images_in_image_set.sort()\n",
    "\n",
    "                for image_name in images_in_image_set:\n",
    "                    image = load_image(os.path.join(image_set_dir, image_name))\n",
    "                    image_set.append(image)\n",
    "\n",
    "                input_image_sets[image_set_name] = image_set\n",
    "\n",
    "\n",
    "def save_image_set(image_set: list, image_set_dir: str):\n",
    "    os.makedirs(image_set_dir, exist_ok=True)\n",
    "    for image in image_set:\n",
    "        # if not jpg or png set to png\n",
    "        filepath = Path(image.filename)\n",
    "        if filepath.suffix not in [\".jpg\", \".png\"]:\n",
    "            output_filename = filepath.stem + \".png\"\n",
    "        else:\n",
    "            output_filename = filepath.name\n",
    "        cv2.imwrite(os.path.join(image_set_dir, output_filename), image.image_color)\n",
    "\n",
    "\n",
    "load_image_sets(input_image_set_dir)\n",
    "load_image_sets(input_image_set_scaled_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image set scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_image_in_image_set(image_set: list) -> np.array:\n",
    "    largest_image = None\n",
    "    largest_pixel_count = 0\n",
    "    for image in image_set:\n",
    "        resolution = image.image_color.shape[:2]\n",
    "        pixel_count = resolution[0] * resolution[1]\n",
    "        if pixel_count > largest_pixel_count:\n",
    "            largest_pixel_count = pixel_count\n",
    "            largest_image = image\n",
    "    return largest_image\n",
    "\n",
    "\n",
    "def get_largest_resolution_in_image_set(image_set: list) -> tuple:\n",
    "    largest_image = get_largest_image_in_image_set(image_set)\n",
    "    return largest_image.image_color.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcfa8aeb958439b902a162d6114ac18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', index=2, layout=Layout(width='max-content'), o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-29 13:24:36.885 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mCreating scaled image set for stitch_the_room \u001b[0mtook: \u001b[31m7.0821 s\u001b[0m \u001b[90m(notebook_cell:49)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def scaler():\n",
    "    clear_output()\n",
    "    KEY_SCALER_IMAGE_SET_DROPDOWN = \"scaler_image_set_dropdown\"\n",
    "    scaler_image_set_dropdown = wid.Dropdown(\n",
    "        options=list(input_image_sets.keys()),\n",
    "        value=memoize.get(\n",
    "            KEY_SCALER_IMAGE_SET_DROPDOWN,\n",
    "            default=next(iter(input_image_sets.keys())),\n",
    "            possible_values=input_image_sets.keys(),\n",
    "        ),\n",
    "        description=\"Image set\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "    scaler_largest_resolution_label = wid.Label(\"Largest image: (X,X)\")\n",
    "    KEY_SCALER_SCALE_SLIDER = \"scaler_scale_slider\"\n",
    "    scaler_scale_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SCALER_SCALE_SLIDER, default=1.0),\n",
    "        min=0.1,\n",
    "        max=30.0,\n",
    "        step=0.1,\n",
    "        continuous_update=True,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Scale\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    scaler_result_resolution_label = wid.Label(\"Resulting largest image: (X,X)\")\n",
    "    scaler_create_scaled_image_set_button = wid.Button(\n",
    "        description=\"Create scaled image set\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "\n",
    "    def on_update_resolution_labels(change=None):\n",
    "        memoize.set(KEY_SCALER_IMAGE_SET_DROPDOWN, scaler_image_set_dropdown.value)\n",
    "        memoize.set(KEY_SCALER_SCALE_SLIDER, scaler_scale_slider.value)\n",
    "\n",
    "        image_set = input_image_sets[scaler_image_set_dropdown.value]\n",
    "        largest_image = get_largest_image_in_image_set(image_set)\n",
    "        largest_resolution = largest_image.image_color.shape[:2]\n",
    "        scaler_largest_resolution_label.value = f\"Largest image: {largest_resolution}\"\n",
    "        scaler_result_resolution_label.value = f\"Resulting largest image: {tuple(int(x * 1/scaler_scale_slider.value) for x in largest_resolution)}\"\n",
    "\n",
    "    scaler_scale_slider.observe(on_update_resolution_labels, names=\"value\")\n",
    "    scaler_image_set_dropdown.observe(on_update_resolution_labels, names=\"value\")\n",
    "    on_update_resolution_labels()\n",
    "\n",
    "    def create_scaled_image_set(change=None):\n",
    "        with LogTimer(\n",
    "            f\"Creating scaled image set for {scaler_image_set_dropdown.value}\"\n",
    "        ):\n",
    "            original_image_set = input_image_sets[scaler_image_set_dropdown.value]\n",
    "\n",
    "            scale = 1 / scaler_scale_slider.value\n",
    "\n",
    "            largest_resolution = get_largest_resolution_in_image_set(original_image_set)\n",
    "            scaled_resolution = tuple(int(x * scale) for x in largest_resolution)\n",
    "            scaled_resolution_fs_string = (\n",
    "                f\"({scaled_resolution[0]},{scaled_resolution[1]})\"\n",
    "            )\n",
    "\n",
    "            scaled_image_set_name = f\"{scaler_image_set_dropdown.value}_scaled_{scaled_resolution_fs_string}\"\n",
    "\n",
    "            scaled_image_set_dir = os.path.join(\n",
    "                input_image_set_scaled_dir, scaled_image_set_name\n",
    "            )\n",
    "\n",
    "            new_image_set = []\n",
    "            for image in original_image_set:\n",
    "                original_height, original_width = image.image_color.shape[:2]\n",
    "\n",
    "                if (\n",
    "                    original_height < scaled_resolution[0]\n",
    "                    or original_width < scaled_resolution[1]\n",
    "                ):\n",
    "                    logging.warning(\n",
    "                        f\"Image {image.filename} is smaller than the scaled resolution {scaled_resolution}. It will not be scaled.\"\n",
    "                    )\n",
    "                    new_image_set.append(image)\n",
    "                    continue\n",
    "\n",
    "                # TODO: make this configurable\n",
    "                # per_image_scale = max(scaled_resolution[0], scaled_resolution[1]) / max(\n",
    "                #    original_height, original_width\n",
    "                # )\n",
    "                per_image_scale = scale\n",
    "\n",
    "                per_image_scaled_resolution = tuple(\n",
    "                    int(x * per_image_scale) for x in image.image_color.shape[:2]\n",
    "                )\n",
    "                per_image_scaled_resolution_fs_string = f\"({per_image_scaled_resolution[0]},{per_image_scaled_resolution[1]})\"\n",
    "                with LogTimer(\n",
    "                    f\"Resizing image {image.filename} from {image.image_color.shape[:2]} to {per_image_scaled_resolution}\"\n",
    "                ):\n",
    "                    new_image = LoadedImage()\n",
    "                    new_image.image_color = cv2.resize(\n",
    "                        image.image_color,\n",
    "                        (\n",
    "                            per_image_scaled_resolution[1],\n",
    "                            per_image_scaled_resolution[0],\n",
    "                        ),\n",
    "                    )\n",
    "                    new_image.filename = f\"{Path(image.filename).stem}_{per_image_scaled_resolution_fs_string}{Path(image.filename).suffix}\"\n",
    "                    new_image_set.append(new_image)\n",
    "\n",
    "            save_image_set(new_image_set, scaled_image_set_dir)\n",
    "            load_image_sets(input_image_set_scaled_dir)\n",
    "            scaler()\n",
    "\n",
    "    scaler_create_scaled_image_set_button.on_click(create_scaled_image_set)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                wid.HBox([scaler_image_set_dropdown, scaler_largest_resolution_label]),\n",
    "                wid.HBox([scaler_scale_slider, scaler_result_resolution_label]),\n",
    "                scaler_create_scaled_image_set_button,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_magenta = tuple([int(x / 2) for x in (255, 0, 255)])\n",
    "\n",
    "\n",
    "def draw_center_lines(image_io: np.ndarray) -> np.ndarray:\n",
    "    height, width = image_io.shape[:2]\n",
    "    cv2.line(image_io, (width // 2, 0), (width // 2, height), (255, 0, 0), 2)\n",
    "    cv2.line(image_io, (0, height // 2), (width, height // 2), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "def image_to_verts(image_i: np.ndarray) -> np.ndarray:\n",
    "    height, width = image_i.shape[:2]\n",
    "    return np.array(\n",
    "        [\n",
    "            [0, 0],\n",
    "            [width, 0],\n",
    "            [width, height],\n",
    "            [0, height],\n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_homography_to_verts(\n",
    "    homography_i: np.ndarray, verts_i: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    return cv2.perspectiveTransform(verts_i.reshape(1, -1, 2), homography_i).reshape(\n",
    "        -1, 2\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_verts(\n",
    "    image_io: np.ndarray,\n",
    "    verts_i: np.ndarray,\n",
    "    thickness=10,\n",
    "    fill_color=None,\n",
    "    outline_color=None,\n",
    ") -> np.ndarray:\n",
    "    if fill_color is not None:\n",
    "        cv2.fillPoly(image_io, [verts_i], fill_color)\n",
    "    if outline_color is None:\n",
    "        line_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]\n",
    "    else:\n",
    "        line_colors = [outline_color] * 4\n",
    "    for i in range(4):\n",
    "        cv2.line(\n",
    "            image_io,\n",
    "            tuple(verts_i[i]),\n",
    "            tuple(verts_i[(i + 1) % 4]),\n",
    "            color=line_colors[i],\n",
    "            thickness=thickness,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Harris Points of Interest detection and Image stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48905c0e6d2a42c6968218252759d227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', layout=Layout(width='max-content'), options=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_width = 16\n",
    "image_size = 512\n",
    "\n",
    "# filter keys by \"stitch\"\n",
    "input_image_sets_stitch = {\n",
    "    key: value for key, value in input_image_sets.items() if \"stitch\" in key\n",
    "}\n",
    "# change the order so that image sets with \"scaled\" are first\n",
    "input_image_sets_stitch = dict(\n",
    "    sorted(\n",
    "        input_image_sets_stitch.items(),\n",
    "        key=lambda item: \"scaled\" not in item[0],\n",
    "    )\n",
    ")\n",
    "\n",
    "KEY_IMAGE_SET_DROPDOWN = \"image_set_dropdown\"\n",
    "image_set_dropdown_options = list(input_image_sets_stitch.keys())\n",
    "image_set_dropdown = wid.Dropdown(\n",
    "    options=image_set_dropdown_options,\n",
    "    value=memoize.get(\n",
    "        KEY_IMAGE_SET_DROPDOWN,\n",
    "        default=image_set_dropdown_options[0],\n",
    "        possible_values=image_set_dropdown_options,\n",
    "    ),\n",
    "    description=\"Image set\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN = \"points_of_interest_impl_dropdown\"\n",
    "points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "output = wid.Output()\n",
    "\n",
    "\n",
    "@output.capture(clear_output=True, wait=True)\n",
    "def on_menu_change(change=None):\n",
    "    memoize.set(KEY_IMAGE_SET_DROPDOWN, image_set_dropdown.value)\n",
    "    memoize.set(\n",
    "        KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN, points_of_interest_impl_dropdown.value\n",
    "    )\n",
    "\n",
    "    # reload the impl module\n",
    "    current_points_of_interest_impl = points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(current_points_of_interest_impl)\n",
    "\n",
    "    input_image_set = input_image_sets_stitch[image_set_dropdown.value]\n",
    "    total_image_count = len(input_image_set)\n",
    "    KEY_IMAGE_COUNT_SLIDER = f\"image_count_slider_{image_set_dropdown.value}\"\n",
    "    current_image_count_slider_value = memoize.get(\n",
    "        KEY_IMAGE_COUNT_SLIDER, default=total_image_count\n",
    "    )\n",
    "    if current_image_count_slider_value > total_image_count:\n",
    "        current_image_count_slider_value = total_image_count\n",
    "    image_count_slider = wid.IntSlider(\n",
    "        value=current_image_count_slider_value,\n",
    "        min=1,\n",
    "        max=total_image_count,\n",
    "        step=1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\"d\",\n",
    "        description=\"Image count\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "\n",
    "    def on_image_count_slider_change(change=None):\n",
    "        memoize.set(KEY_IMAGE_COUNT_SLIDER, image_count_slider.value)\n",
    "        on_menu_change()\n",
    "\n",
    "    image_count_slider.observe(on_image_count_slider_change, names=\"value\")\n",
    "    display(image_count_slider)\n",
    "\n",
    "    image_set = input_image_set[: image_count_slider.value]\n",
    "\n",
    "    with LogTimer(\"Displaying input images\"):\n",
    "        input_ipy_images_color = [\n",
    "            to_ipy_image(image.image_color, longest_side=image_size, upscale=True)\n",
    "            for image in image_set\n",
    "        ]\n",
    "        display(wid.HBox(input_ipy_images_color))\n",
    "        input_ipy_images_gray = [\n",
    "            to_ipy_image(image.image_gray, longest_side=image_size, upscale=True)\n",
    "            for image in image_set\n",
    "        ]\n",
    "        display(wid.HBox(input_ipy_images_gray))\n",
    "\n",
    "    KEY_SIGMA1_SLIDER = \"sigma1_slider\"\n",
    "    sigma1_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SIGMA1_SLIDER, default=0.8),\n",
    "        min=0.1,\n",
    "        max=20.0,\n",
    "        step=0.1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Sigma 1\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_SIGMA2_SLIDER = \"sigma2_slider\"\n",
    "    sigma2_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SIGMA2_SLIDER, default=1.5),\n",
    "        min=0.1,\n",
    "        max=20.0,\n",
    "        step=0.1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Sigma 2\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_THRESHOLD_SLIDER = \"threshold_slider\"\n",
    "    threshold_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_THRESHOLD_SLIDER, default=0.01),\n",
    "        min=0.0,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".2f\",\n",
    "        description=\"Threshold\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_HARRIS_K_SLIDER = \"harris_k_slider\"\n",
    "    harris_k_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_HARRIS_K_SLIDER, default=0.04),\n",
    "        min=0.01,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".2f\",\n",
    "        description=\"Harris k\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    default_harris_button = wid.Button(\n",
    "        description=\"Default Harris\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "    output_harris_corner = wid.Output()\n",
    "\n",
    "    @output_harris_corner.capture(clear_output=True, wait=True)\n",
    "    def on_harris_change(config=None):\n",
    "        memoize.set(KEY_SIGMA1_SLIDER, sigma1_slider.value)\n",
    "        memoize.set(KEY_SIGMA2_SLIDER, sigma2_slider.value)\n",
    "        memoize.set(KEY_THRESHOLD_SLIDER, threshold_slider.value)\n",
    "        memoize.set(KEY_HARRIS_K_SLIDER, harris_k_slider.value)\n",
    "\n",
    "        image_gray_array = np.stack([image.image_gray for image in image_set])\n",
    "        image_color_array = np.stack([image.image_color for image in image_set])\n",
    "\n",
    "        with LogTimer(\"Calculating Harris corners\"):\n",
    "            harris_corner_keystones = points_of_interest_impl.harris_corner(\n",
    "                image_gray_array,\n",
    "                sigma1_slider.value,\n",
    "                sigma2_slider.value,\n",
    "                harris_k_slider.value,\n",
    "                threshold_slider.value,\n",
    "            )\n",
    "\n",
    "        with LogTimer(\"Displaying Harris corners\"):\n",
    "            annotated_harris_ipy_images = []\n",
    "            for image_idx, image in enumerate(image_set):\n",
    "                keypoint_size = int(max(image.image_color.shape[:2]) / 512)\n",
    "                for keypoint in harris_corner_keystones[image_idx]:\n",
    "                    keypoint.size *= keypoint_size\n",
    "\n",
    "                annotated_image = draw_keypoints(\n",
    "                    image_color_array[image_idx],\n",
    "                    harris_corner_keystones[image_idx],\n",
    "                )\n",
    "                annotated_harris_ipy_images.append(\n",
    "                    wid.VBox(\n",
    "                        [\n",
    "                            wid.Label(f\"{image.filename}\"),\n",
    "                            wid.Label(\n",
    "                                f\"Found {len(harris_corner_keystones[image_idx])} Harris corners\"\n",
    "                            ),\n",
    "                            to_ipy_image(\n",
    "                                annotated_image, longest_side=image_size, upscale=True\n",
    "                            ),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            display(wid.HTML(\"<h2>Harris corners</h2>\"))\n",
    "            display(wid.HBox(annotated_harris_ipy_images))\n",
    "\n",
    "            if total_image_count < 2:\n",
    "                display(wid.HTML(\"<h2>Not enough images to calculate matches</h2>\"))\n",
    "                return\n",
    "            # Flann based matcher\n",
    "            display(wid.HTML(\"<h2>Flann matches</h2>\"))\n",
    "            KEY_FLANN_IMAGE_1_DROPDOWN = \"flann_image_1_dropdown\"\n",
    "            flann_image_1_dropdown = wid.Dropdown(\n",
    "                options=[image.filename for image in image_set],\n",
    "                value=memoize.get(\n",
    "                    KEY_FLANN_IMAGE_1_DROPDOWN,\n",
    "                    default=image_set[0].filename,\n",
    "                    possible_values=[image.filename for image in image_set],\n",
    "                ),\n",
    "                description=\"Image 1\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_FLANN_IMAGE_2_DROPDOWN = \"flann_image_2_dropdown\"\n",
    "            flann_image_2_dropdown = wid.Dropdown(\n",
    "                options=[image.filename for image in image_set],\n",
    "                value=memoize.get(\n",
    "                    KEY_FLANN_IMAGE_2_DROPDOWN,\n",
    "                    default=image_set[1].filename,\n",
    "                    possible_values=[image.filename for image in image_set],\n",
    "                ),\n",
    "                description=\"Image 2\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_PATCH_SIZE_SLIDER = \"patch_size_slider\"\n",
    "            patch_size_slider = wid.IntSlider(\n",
    "                value=memoize.get(KEY_PATCH_SIZE_SLIDER, default=5),\n",
    "                min=1,\n",
    "                max=15,\n",
    "                step=1,\n",
    "                continuous_update=False,\n",
    "                orientation=\"horizontal\",\n",
    "                readout=True,\n",
    "                readout_format=\"d\",\n",
    "                description=\"Patch size\",\n",
    "                **widgets_styling_slider,\n",
    "            )\n",
    "            default_flann_button = wid.Button(\n",
    "                description=\"Default flann values\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            output_flann = wid.Output()\n",
    "\n",
    "            @output_flann.capture(clear_output=True, wait=True)\n",
    "            def on_flann_change(config=None):\n",
    "                memoize.set(KEY_FLANN_IMAGE_1_DROPDOWN, flann_image_1_dropdown.value)\n",
    "                memoize.set(KEY_FLANN_IMAGE_2_DROPDOWN, flann_image_2_dropdown.value)\n",
    "                memoize.set(KEY_PATCH_SIZE_SLIDER, patch_size_slider.value)\n",
    "\n",
    "                image_1_idx = [image.filename for image in image_set].index(\n",
    "                    flann_image_1_dropdown.value\n",
    "                )\n",
    "                image_2_idx = [image.filename for image in image_set].index(\n",
    "                    flann_image_2_dropdown.value\n",
    "                )\n",
    "\n",
    "                image_gray_1 = image_gray_array[image_1_idx]\n",
    "                image_gray_2 = image_gray_array[image_2_idx]\n",
    "\n",
    "                keypoints_1 = harris_corner_keystones[image_1_idx]\n",
    "                keypoints_2 = harris_corner_keystones[image_2_idx]\n",
    "\n",
    "                with LogTimer(\"Compute Descriptors\"):\n",
    "                    filtered_keypoints_1, descriptors_1 = (\n",
    "                        points_of_interest_impl.compute_descriptors(\n",
    "                            image_gray_1, keypoints_1, patch_size_slider.value\n",
    "                        )\n",
    "                    )\n",
    "                    filtered_keypoints_2, descriptors_2 = (\n",
    "                        points_of_interest_impl.compute_descriptors(\n",
    "                            image_gray_2, keypoints_2, patch_size_slider.value\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Calculating Flann matches\"):\n",
    "                    matches = points_of_interest_impl.flann_matches(\n",
    "                        descriptors_1, descriptors_2\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Filtering Flann matches\"):\n",
    "                    matches_filtered = points_of_interest_impl.filter_matches(matches)\n",
    "\n",
    "                display(\n",
    "                    f\"Detected {len(matches)} matches, filtered down to {len(matches_filtered)} ({len(matches_filtered)/len(matches)*100:.2f}%)\"\n",
    "                )\n",
    "\n",
    "                with LogTimer(\"Drawing Flann matches\"):\n",
    "                    draw_matches_image = draw_matches(\n",
    "                        image_color_array[image_1_idx],\n",
    "                        filtered_keypoints_1,\n",
    "                        image_color_array[image_2_idx],\n",
    "                        filtered_keypoints_2,\n",
    "                        matches_filtered,\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Displaying Flann matches\"):\n",
    "                    display(\n",
    "                        to_ipy_image(\n",
    "                            draw_matches_image,\n",
    "                            longest_side=image_size * 3,\n",
    "                            upscale=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                KEY_STITCH_START_IMAGE_DROPDOWN = \"stitch_start_image_dropdown\"\n",
    "                stitch_start_image_dropdown = wid.Dropdown(\n",
    "                    options=[image.filename for image in image_set],\n",
    "                    value=memoize.get(\n",
    "                        KEY_STITCH_START_IMAGE_DROPDOWN,\n",
    "                        default=image_set[0].filename,\n",
    "                        possible_values=[image.filename for image in image_set],\n",
    "                    ),\n",
    "                    description=\"Start image\",\n",
    "                    **widgets_styling,\n",
    "                )\n",
    "                KEY_STITCH_RANSAC_CONFIDENCE_SLIDER = \"stitch_ransac_confidence_slider\"\n",
    "                stitch_ransac_confidence_slider = wid.FloatSlider(\n",
    "                    value=memoize.get(\n",
    "                        KEY_STITCH_RANSAC_CONFIDENCE_SLIDER, default=0.99\n",
    "                    ),\n",
    "                    min=0.01,\n",
    "                    max=0.99,\n",
    "                    step=0.01,\n",
    "                    continuous_update=False,\n",
    "                    orientation=\"horizontal\",\n",
    "                    readout=True,\n",
    "                    readout_format=\".2f\",\n",
    "                    description=\"RANSAC confidence\",\n",
    "                    **widgets_styling_slider,\n",
    "                )\n",
    "                KEY_STITCH_INLIER_THRESHOLD_SLIDER = \"stitch_inlier_threshold_slider\"\n",
    "                stitch_inlier_threshold_slider = wid.FloatSlider(\n",
    "                    value=memoize.get(KEY_STITCH_INLIER_THRESHOLD_SLIDER, default=5.0),\n",
    "                    min=0.1,\n",
    "                    max=10.0,\n",
    "                    step=0.1,\n",
    "                    continuous_update=False,\n",
    "                    orientation=\"horizontal\",\n",
    "                    readout=True,\n",
    "                    readout_format=\".1f\",\n",
    "                    description=\"RANSAC inlier threshold\",\n",
    "                    **widgets_styling_slider,\n",
    "                )\n",
    "                stitch_output = wid.Output()\n",
    "\n",
    "                @stitch_output.capture(clear_output=True, wait=True)\n",
    "                def on_stitch_change(config=None):\n",
    "                    memoize.set(\n",
    "                        KEY_STITCH_START_IMAGE_DROPDOWN,\n",
    "                        stitch_start_image_dropdown.value,\n",
    "                    )\n",
    "                    memoize.set(\n",
    "                        KEY_STITCH_RANSAC_CONFIDENCE_SLIDER,\n",
    "                        stitch_ransac_confidence_slider.value,\n",
    "                    )\n",
    "                    memoize.set(\n",
    "                        KEY_STITCH_INLIER_THRESHOLD_SLIDER,\n",
    "                        stitch_inlier_threshold_slider.value,\n",
    "                    )\n",
    "\n",
    "                    with LogTimer(\"Stitching images\"):\n",
    "                        # image stitching\n",
    "                        initial_image_idx = [\n",
    "                            image.filename for image in image_set\n",
    "                        ].index(stitch_start_image_dropdown.value)\n",
    "\n",
    "                        remaining_images = [\n",
    "                            image\n",
    "                            for image in image_set\n",
    "                            if image != image_set[initial_image_idx]\n",
    "                        ]\n",
    "                        # TODO: allow the order to be configured\n",
    "                        # remaining_images = list(reversed(remaining_images))\n",
    "\n",
    "                        failed_images = []\n",
    "\n",
    "                        stitched_image = image_color_array[initial_image_idx].copy()\n",
    "                        while remaining_images:\n",
    "                            image = remaining_images.pop(0)\n",
    "                            with LogTimer(f\"Stitching image {image.filename}\"):\n",
    "                                image_idx = [\n",
    "                                    image.filename for image in image_set\n",
    "                                ].index(image.filename)\n",
    "\n",
    "                                stitched_image_gray = cv2.cvtColor(\n",
    "                                    stitched_image, cv2.COLOR_BGR2GRAY\n",
    "                                )\n",
    "\n",
    "                                stitched_keypoints = (\n",
    "                                    points_of_interest_impl.harris_corner(\n",
    "                                        [stitched_image_gray],\n",
    "                                        sigma1_slider.value,\n",
    "                                        sigma2_slider.value,\n",
    "                                        harris_k_slider.value,\n",
    "                                        threshold_slider.value,\n",
    "                                    )[0]\n",
    "                                )\n",
    "                                stitched_filtered_keypoints, stitched_descriptors = (\n",
    "                                    points_of_interest_impl.compute_descriptors(\n",
    "                                        stitched_image_gray,\n",
    "                                        stitched_keypoints,\n",
    "                                        patch_size_slider.value,\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                                keypoints = harris_corner_keystones[image_idx]\n",
    "                                filtered_keypoints, descriptors = (\n",
    "                                    points_of_interest_impl.compute_descriptors(\n",
    "                                        image_gray_array[image_idx],\n",
    "                                        keypoints,\n",
    "                                        patch_size_slider.value,\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                                matches = points_of_interest_impl.flann_matches(\n",
    "                                    descriptors, stitched_descriptors\n",
    "                                )\n",
    "                                filtered_matches = (\n",
    "                                    points_of_interest_impl.filter_matches(matches)\n",
    "                                )\n",
    "\n",
    "                                source_points = np.array(\n",
    "                                    [\n",
    "                                        filtered_keypoints[match.queryIdx].pt\n",
    "                                        for match in filtered_matches\n",
    "                                    ],\n",
    "                                    dtype=np.float32,\n",
    "                                )\n",
    "                                target_points = np.array(\n",
    "                                    [\n",
    "                                        stitched_filtered_keypoints[match.trainIdx].pt\n",
    "                                        for match in filtered_matches\n",
    "                                    ],\n",
    "                                    dtype=np.float32,\n",
    "                                )\n",
    "\n",
    "                                homography_result = (\n",
    "                                    points_of_interest_impl.find_homography_ransac(\n",
    "                                        source_points,\n",
    "                                        target_points,\n",
    "                                        stitch_ransac_confidence_slider.value,\n",
    "                                        stitch_inlier_threshold_slider.value,\n",
    "                                    )\n",
    "                                )\n",
    "                                homography = homography_result.homography\n",
    "                                if homography is None:\n",
    "                                    display(\n",
    "                                        f\"Failed to find homography for image {image.filename} adding to failed images. Will retry on another successful stitch\"\n",
    "                                    )\n",
    "                                    failed_images.append(image)\n",
    "                                    continue\n",
    "\n",
    "                                # Calculate the four corners of the image in the stitched image\n",
    "                                image_corners = image_to_verts(image.image_color)\n",
    "                                image_corners = image_corners.astype(np.float32)\n",
    "                                # ic(image_corners)\n",
    "                                image_corners_homography = apply_homography_to_verts(\n",
    "                                    homography, image_corners\n",
    "                                )\n",
    "                                image_left_most = -min(\n",
    "                                    np.min(image_corners_homography[:, 0]), 0\n",
    "                                )\n",
    "                                image_right_most = max(\n",
    "                                    np.max(image_corners_homography[:, 0]), 0\n",
    "                                )\n",
    "                                image_top_most = -min(\n",
    "                                    np.min(image_corners_homography[:, 1]), 0\n",
    "                                )\n",
    "                                image_bottom_most = max(\n",
    "                                    np.max(image_corners_homography[:, 1]), 0\n",
    "                                )\n",
    "\n",
    "                                # TODO: the image might get very big during stitching.\n",
    "                                # Two solutions:\n",
    "                                # 1) scale it down\n",
    "                                # 2) Split the image into windows on the borders and try to stitch to those\n",
    "\n",
    "                                # Grow the stitched image to fit the new image\n",
    "                                stitched_height, stitched_width = stitched_image.shape[\n",
    "                                    :2\n",
    "                                ]\n",
    "                                # pad the stitched image\n",
    "                                pad_left = int(max(image_left_most, 0))\n",
    "                                pad_right = int(\n",
    "                                    max(image_right_most - stitched_width, 0)\n",
    "                                )\n",
    "                                pad_top = int(max(image_top_most, 0))\n",
    "                                pad_bottom = int(\n",
    "                                    max(image_bottom_most - stitched_height, 0)\n",
    "                                )\n",
    "\n",
    "                                if (\n",
    "                                    False\n",
    "                                    and pad_left == 0\n",
    "                                    and pad_right == 0\n",
    "                                    and pad_top == 0\n",
    "                                    and pad_bottom == 0\n",
    "                                ):\n",
    "                                    # TODO: make this optional\n",
    "                                    # This can have negative effects because stitching consecutive images that don't extend the stitched image\n",
    "                                    # can still reduce the perspective distortion and allow other images to be stitched\n",
    "                                    display(\n",
    "                                        f\"Image {image.filename} would not add any new information to the stitched image. Skipping\"\n",
    "                                    )\n",
    "                                    continue\n",
    "\n",
    "                                # ic(\n",
    "                                #    f\"pad_left: {pad_left}, pad_right: {pad_right}, pad_top: {pad_top}, pad_bottom: {pad_bottom}\"\n",
    "                                # )\n",
    "                                stitched_image = cv2.copyMakeBorder(\n",
    "                                    stitched_image,\n",
    "                                    pad_top,\n",
    "                                    pad_bottom,\n",
    "                                    pad_left,\n",
    "                                    pad_right,\n",
    "                                    cv2.BORDER_CONSTANT,\n",
    "                                    value=(0, 0, 0),\n",
    "                                )\n",
    "\n",
    "                                debug = False\n",
    "\n",
    "                                # add translation to homography\n",
    "                                translation = np.eye(3, 3)\n",
    "                                translation[0, 2] = pad_left\n",
    "                                translation[1, 2] = pad_top\n",
    "                                homography = translation @ homography\n",
    "\n",
    "                                # Apply the homography to the new image\n",
    "                                image_homography = cv2.warpPerspective(\n",
    "                                    image.image_color,\n",
    "                                    homography,\n",
    "                                    (stitched_image.shape[1], stitched_image.shape[0]),\n",
    "                                )\n",
    "\n",
    "                                # Add the new image to the stitched image\n",
    "                                # a binary mask creates ugly black borders\n",
    "\n",
    "                                # https://stackoverflow.com/a/68641183/4479969\n",
    "                                mask = cv2.threshold(\n",
    "                                    image_homography, 0, 255, cv2.THRESH_BINARY\n",
    "                                )[1]\n",
    "                                kernel = cv2.getStructuringElement(\n",
    "                                    cv2.MORPH_ELLIPSE, (3, 3)\n",
    "                                )\n",
    "                                mask = cv2.morphologyEx(mask, cv2.MORPH_ERODE, kernel)\n",
    "                                image_homography[mask == 0] = 0\n",
    "\n",
    "                                cv2.copyTo(\n",
    "                                    src=image_homography,\n",
    "                                    mask=image_homography,\n",
    "                                    dst=stitched_image,\n",
    "                                )\n",
    "\n",
    "                                if debug:\n",
    "                                    display(\n",
    "                                        to_ipy_image(\n",
    "                                            image_homography,\n",
    "                                            longest_side=image_size,\n",
    "                                            upscale=True,\n",
    "                                        )\n",
    "                                    )\n",
    "                                    display(\n",
    "                                        to_ipy_image(\n",
    "                                            stitched_image,\n",
    "                                            longest_side=image_size * 2,\n",
    "                                            upscale=True,\n",
    "                                        )\n",
    "                                    )\n",
    "                                    # show matches\n",
    "                                    draw_matches_image = draw_matches(\n",
    "                                        image.image_color,\n",
    "                                        keypoints,\n",
    "                                        stitched_image,\n",
    "                                        stitched_keypoints,\n",
    "                                        filtered_matches,\n",
    "                                    )\n",
    "                                    display(\n",
    "                                        to_ipy_image(\n",
    "                                            draw_matches_image,\n",
    "                                            longest_side=image_size * 2,\n",
    "                                            upscale=True,\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                remaining_images = remaining_images + failed_images\n",
    "                                failed_images = []\n",
    "\n",
    "                        # Draw the stitched image\n",
    "                        display(\n",
    "                            f\"Stitched image with {len(image_set) - len(failed_images)} images and {len(failed_images)} failed images\"\n",
    "                        )\n",
    "                        display(\n",
    "                            to_ipy_image(\n",
    "                                stitched_image,\n",
    "                                longest_side=image_size * 2,\n",
    "                                upscale=True,\n",
    "                            )\n",
    "                        )\n",
    "                        save_image_button = wid.Button(\n",
    "                            description=\"Save stitched image\",\n",
    "                            **widgets_styling,\n",
    "                        )\n",
    "\n",
    "                        def on_save_image_button_click(change=None):\n",
    "                            os.makedirs(\"./stitched_images\", exist_ok=True)\n",
    "                            time_str = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            save_image(\n",
    "                                stitched_image,\n",
    "                                f\"./stitched_images/stitched_{time_str}_{image_set_dropdown.value}.png\",\n",
    "                            )\n",
    "\n",
    "                        save_image_button.on_click(on_save_image_button_click)\n",
    "                        display(save_image_button)\n",
    "\n",
    "                stitch_start_image_dropdown.observe(on_stitch_change, names=\"value\")\n",
    "\n",
    "                display(\n",
    "                    wid.VBox(\n",
    "                        [\n",
    "                            wid.VBox(\n",
    "                                [\n",
    "                                    stitch_start_image_dropdown,\n",
    "                                    stitch_ransac_confidence_slider,\n",
    "                                    stitch_inlier_threshold_slider,\n",
    "                                ]\n",
    "                            ),\n",
    "                            stitch_output,\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                on_stitch_change()\n",
    "\n",
    "            flann_image_1_dropdown.observe(on_flann_change, names=\"value\")\n",
    "            flann_image_2_dropdown.observe(on_flann_change, names=\"value\")\n",
    "            patch_size_slider.observe(on_flann_change, names=\"value\")\n",
    "\n",
    "            def default_flann(change=None):\n",
    "                memoize.delete_keys(\n",
    "                    [\n",
    "                        KEY_FLANN_IMAGE_1_DROPDOWN,\n",
    "                        KEY_FLANN_IMAGE_2_DROPDOWN,\n",
    "                        KEY_PATCH_SIZE_SLIDER,\n",
    "                    ]\n",
    "                )\n",
    "                on_menu_change()\n",
    "\n",
    "            default_flann_button.on_click(default_flann)\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HBox([flann_image_1_dropdown, flann_image_2_dropdown]),\n",
    "                        wid.HBox([patch_size_slider, default_flann_button]),\n",
    "                        output_flann,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_flann_change()\n",
    "\n",
    "    sigma1_slider.observe(on_harris_change, names=\"value\")\n",
    "    sigma2_slider.observe(on_harris_change, names=\"value\")\n",
    "    threshold_slider.observe(on_harris_change, names=\"value\")\n",
    "    harris_k_slider.observe(on_harris_change, names=\"value\")\n",
    "\n",
    "    def default_harris(change=None):\n",
    "        memoize.delete_keys(\n",
    "            [\n",
    "                KEY_SIGMA1_SLIDER,\n",
    "                KEY_SIGMA2_SLIDER,\n",
    "                KEY_THRESHOLD_SLIDER,\n",
    "                KEY_HARRIS_K_SLIDER,\n",
    "            ]\n",
    "        )\n",
    "        on_menu_change()\n",
    "\n",
    "    default_harris_button.on_click(default_harris)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                sigma1_slider,\n",
    "                sigma2_slider,\n",
    "                threshold_slider,\n",
    "                harris_k_slider,\n",
    "                default_harris_button,\n",
    "                output_harris_corner,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    on_harris_change()\n",
    "\n",
    "\n",
    "image_set_dropdown.observe(on_menu_change, names=\"value\")\n",
    "points_of_interest_impl_dropdown.observe(on_menu_change, names=\"value\")\n",
    "reload_impl_button.on_click(on_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    image_set_dropdown,\n",
    "                    points_of_interest_impl_dropdown,\n",
    "                    reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_menu_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Homography Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ead95b0d46a40f58415cd2b19f4fa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Point of interest implementation', layout=Layout(width='ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Allow other homography implementations to be selected\n",
    "\n",
    "KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN = (\n",
    "    \"homography_d_points_of_interest_impl_dropdown\"\n",
    ")\n",
    "homography_d_points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_HOMOGRAPHY_D_USE_SVD_CHECKBOX = \"homography_d_use_svd_checkbox\"\n",
    "homography_d_use_svd_checkbox = wid.Checkbox(\n",
    "    value=memoize.get(KEY_HOMOGRAPHY_D_USE_SVD_CHECKBOX, default=True),\n",
    "    description=\"Use SVD\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "homography_d_reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "homography_d_output = wid.Output()\n",
    "\n",
    "\n",
    "def random_rectangle_transform(\n",
    "    image_i: np.ndarray, rectangle_verts_i: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create a random rectangle in the image and return its vertices in the image and in the object space.\n",
    "\n",
    "    :return: (generated_image, target_points, source_points):\n",
    "        generated_image: image with a single projected rectangle\n",
    "        target_points: array of keypoints_1 in the target image in the shape (n, 2)\n",
    "        source_points: array of keypoints_1 in the source image in the shape (n, 2)\n",
    "    :rtype: (np.ndarray, np.ndarray, np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    image_height, image_width = image_i.shape[:2]\n",
    "\n",
    "    # Compute the height and width of the rectangle from its vertices\n",
    "    min_coords = np.min(rectangle_verts_i, axis=0)\n",
    "    max_coords = np.max(rectangle_verts_i, axis=0)\n",
    "    rect_width = max_coords[0] - min_coords[0]\n",
    "    rect_height = max_coords[1] - min_coords[1]\n",
    "\n",
    "    # Move the rectangle to the center of the scene\n",
    "    image_rectangle_verts = (\n",
    "        rectangle_verts_i\n",
    "        + [\n",
    "            image_width / 2.0 - rect_width / 2.0,\n",
    "            image_height / 2.0 - rect_height / 2.0,\n",
    "        ]\n",
    "        + np.around(10 * np.random.randn(4, 2))\n",
    "    )\n",
    "    image_rectangle_verts = image_rectangle_verts.astype(np.int32)\n",
    "\n",
    "    return image_rectangle_verts\n",
    "\n",
    "\n",
    "def draw_projected_object(\n",
    "    image_io: np.ndarray,\n",
    "    object_image_i: np.ndarray,\n",
    "    homography_i: np.ndarray,\n",
    "    draw_object=True,\n",
    "    fill_color=color_magenta,\n",
    "    outline_color=None,\n",
    ") -> np.ndarray:\n",
    "    # Get the vertices of the object image\n",
    "    object_verts_i = image_to_verts(object_image_i).astype(np.float32)\n",
    "\n",
    "    # Project the object image to the input image\n",
    "    # We have to reshape because openCV expects batched input\n",
    "    projected_verts_i = (\n",
    "        cv2.perspectiveTransform(object_verts_i.reshape(1, -1, 2), homography_i)\n",
    "        .reshape(-1, 2)\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "\n",
    "    draw_verts(\n",
    "        image_io,\n",
    "        projected_verts_i,\n",
    "        thickness=2,\n",
    "        fill_color=fill_color,\n",
    "        outline_color=outline_color,\n",
    "    )\n",
    "\n",
    "    if draw_object:\n",
    "        # Draw the object image in the projected position\n",
    "        object_image_p = cv2.warpPerspective(\n",
    "            object_image_i,\n",
    "            homography_i,\n",
    "            (image_io.shape[1], image_io.shape[0]),\n",
    "        )\n",
    "\n",
    "        cv2.copyTo(src=object_image_p, mask=object_image_p, dst=image_io)\n",
    "\n",
    "\n",
    "@homography_d_output.capture(clear_output=True, wait=True)\n",
    "def on_homography_d_menu_change(change=None):\n",
    "    memoize.set(\n",
    "        KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        homography_d_points_of_interest_impl_dropdown.value,\n",
    "    )\n",
    "    impl_name = homography_d_points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(impl_name)\n",
    "\n",
    "    test_scene_image_height, test_scene_width = 320, 480\n",
    "    test_scene_image = np.zeros(\n",
    "        shape=(test_scene_image_height, test_scene_width, 3),\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "\n",
    "    object_image = np.full(\n",
    "        shape=(120, 200, 3), dtype=np.uint8, fill_value=color_magenta\n",
    "    )\n",
    "    draw_center_lines(object_image)\n",
    "    object_verts = image_to_verts(object_image)\n",
    "\n",
    "    # draw_center_lines(test_scene_image)\n",
    "\n",
    "    image_rectangle_verts = random_rectangle_transform(test_scene_image, object_verts)\n",
    "    draw_verts(test_scene_image, image_rectangle_verts)\n",
    "\n",
    "    display(to_ipy_image(test_scene_image, longest_side=image_size, upscale=True))\n",
    "\n",
    "    with LogTimer(\"Calculating homography\"):\n",
    "        homography = points_of_interest_impl.find_homography_eq(\n",
    "            object_verts,\n",
    "            image_rectangle_verts,\n",
    "            use_svd=homography_d_use_svd_checkbox.value,\n",
    "        ).homography\n",
    "\n",
    "    draw_projected_object(test_scene_image, object_image, homography)\n",
    "    display(to_ipy_image(test_scene_image, longest_side=image_size, upscale=True))\n",
    "\n",
    "\n",
    "homography_d_points_of_interest_impl_dropdown.observe(\n",
    "    on_homography_d_menu_change, names=\"value\"\n",
    ")\n",
    "homography_d_use_svd_checkbox.observe(on_homography_d_menu_change, names=\"value\")\n",
    "homography_d_reload_impl_button.on_click(on_homography_d_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    homography_d_points_of_interest_impl_dropdown,\n",
    "                    homography_d_use_svd_checkbox,\n",
    "                    homography_d_reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            homography_d_output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_homography_d_menu_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find objects using RANSAC and SIFT and Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0af8bdf0623434da59367f54ba3f9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', index=1, layout=Layout(width='max-content'), o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter keys by \"objects\"\n",
    "input_image_sets_objects = {\n",
    "    key: value for key, value in input_image_sets.items() if \"objects\" in key\n",
    "}\n",
    "# change the order so that image sets with \"scaled\" are first\n",
    "input_image_sets_objects = dict(\n",
    "    sorted(\n",
    "        input_image_sets_objects.items(),\n",
    "        key=lambda item: \"scaled\" not in item[0],\n",
    "    )\n",
    ")\n",
    "\n",
    "KEY_FINDER_IMAGE_SET_DROPDOWN = \"finder_image_set_dropdown\"\n",
    "finder_image_set_dropdown = wid.Dropdown(\n",
    "    options=list(input_image_sets_objects.keys()),\n",
    "    value=memoize.get(\n",
    "        KEY_FINDER_IMAGE_SET_DROPDOWN,\n",
    "        default=next(iter(input_image_sets_objects.keys())),\n",
    "        possible_values=input_image_sets_objects.keys(),\n",
    "    ),\n",
    "    description=\"Image set\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN = \"finder_points_of_interest_impl_dropdown\"\n",
    "finder_points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "finder_reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "finder_output = wid.Output()\n",
    "\n",
    "\n",
    "@finder_output.capture(clear_output=True, wait=False)\n",
    "def on_finder_menu_change(change=None):\n",
    "    memoize.set(KEY_FINDER_IMAGE_SET_DROPDOWN, finder_image_set_dropdown.value)\n",
    "    memoize.set(\n",
    "        KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        finder_points_of_interest_impl_dropdown.value,\n",
    "    )\n",
    "\n",
    "    # reload the impl module\n",
    "    current_points_of_interest_impl = finder_points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(current_points_of_interest_impl)\n",
    "\n",
    "    color_it = bgrs()\n",
    "\n",
    "    # extract scene images from the set\n",
    "    with LogTimer(\"Loading scene images\"):\n",
    "        scene_images = [\n",
    "            image\n",
    "            for image in input_image_sets_objects[finder_image_set_dropdown.value]\n",
    "            if \"scene\" in image.filename\n",
    "        ]\n",
    "        scene_image_wids = [\n",
    "            to_ipy_image(\n",
    "                image.image_color,\n",
    "                longest_side=image_size / 3,\n",
    "                upscale=True,\n",
    "                set_dimensions=True,\n",
    "            )\n",
    "            for image in scene_images\n",
    "        ]\n",
    "        scene_images_filenames = [image.filename for image in scene_images]\n",
    "\n",
    "    KEY_FINDER_SCENE_IMAGE_SELECT = \"finder_scene_image_select\"\n",
    "    finder_scene_image_select = RadioSelect(\n",
    "        all_choices=scene_images_filenames,\n",
    "        default_choice=memoize.get(\n",
    "            KEY_FINDER_SCENE_IMAGE_SELECT,\n",
    "            default=scene_images_filenames[0],\n",
    "            possible_values=scene_images_filenames,\n",
    "        ),\n",
    "        custom_widgets=scene_image_wids,\n",
    "        grid_template_columns=\"1fr 1fr 1fr 1fr 1fr\",\n",
    "    )\n",
    "\n",
    "    # extract object images from the set\n",
    "    with LogTimer(\"Loading object images\"):\n",
    "        object_images = [\n",
    "            image\n",
    "            for image in input_image_sets_objects[finder_image_set_dropdown.value]\n",
    "            if \"object\" in image.filename\n",
    "        ]\n",
    "        object_colors = [next(color_it) for _ in object_images]\n",
    "        # multiply the color by 255 to get the color in the range 0-255\n",
    "        object_colors = [\n",
    "            (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)) for x in object_colors\n",
    "        ]\n",
    "        border_width = 10\n",
    "        framed_object_images = [\n",
    "            cv2.copyMakeBorder(\n",
    "                image.image_color,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                cv2.BORDER_CONSTANT,\n",
    "                value=color,\n",
    "            )\n",
    "            for image, color in zip(object_images, object_colors)\n",
    "        ]\n",
    "        object_image_wids = [\n",
    "            to_ipy_image(\n",
    "                image,\n",
    "                longest_side=image_size / 3,\n",
    "                upscale=True,\n",
    "                set_dimensions=True,\n",
    "            )\n",
    "            for image in framed_object_images\n",
    "        ]\n",
    "        object_images_filenames = [image.filename for image in object_images]\n",
    "\n",
    "    if len(object_images_filenames) == 0:\n",
    "        display(wid.HTML(\"<h2>No object images found in the set</h2>\"))\n",
    "        return\n",
    "\n",
    "    KEY_FINDER_OBJECT_IMAGE_SELECT = \"finder_object_image_select1\"\n",
    "    finder_object_image_select = MultiSelect(\n",
    "        all_choices=object_images_filenames,\n",
    "        default_choices=memoize.get(\n",
    "            KEY_FINDER_OBJECT_IMAGE_SELECT,\n",
    "            default=object_images_filenames[0],\n",
    "            possible_values=object_images_filenames,\n",
    "            multi_value=True,\n",
    "        ),\n",
    "        custom_widgets=object_image_wids,\n",
    "        grid_template_columns=\"1fr 1fr 1fr 1fr 1fr\",\n",
    "    )\n",
    "\n",
    "    finder_image_selection_output = wid.Output()\n",
    "\n",
    "    @finder_image_selection_output.capture(clear_output=True, wait=False)\n",
    "    def on_finder_image_selection_change(change=None):\n",
    "        memoize.set(\n",
    "            KEY_FINDER_OBJECT_IMAGE_SELECT, finder_object_image_select.get_selected()\n",
    "        )\n",
    "        memoize.set(\n",
    "            KEY_FINDER_SCENE_IMAGE_SELECT, finder_scene_image_select.get_selected()\n",
    "        )\n",
    "\n",
    "        scene_image_selected = scene_images[\n",
    "            scene_images_filenames.index(finder_scene_image_select.get_selected())\n",
    "        ]\n",
    "        scene_image_selected_gray = scene_image_selected.image_gray\n",
    "\n",
    "        object_images_selected_indices = [\n",
    "            object_images_filenames.index(filename)\n",
    "            for filename in finder_object_image_select.get_selected()\n",
    "        ]\n",
    "        object_images_selected = [\n",
    "            object_images[index] for index in object_images_selected_indices\n",
    "        ]\n",
    "        object_images_selected_gray = [\n",
    "            image.image_gray for image in object_images_selected\n",
    "        ]\n",
    "\n",
    "        with LogTimer(\"Running sift\"):\n",
    "            object_recognition_result = points_of_interest_impl.run_object_recognition(\n",
    "                object_images_selected_gray, [scene_image_selected_gray]\n",
    "            )\n",
    "\n",
    "        object_images_selected_filenames = [\n",
    "            image.filename for image in object_images_selected\n",
    "        ]\n",
    "\n",
    "        # Show the sift result\n",
    "        if len(object_images_selected) != 0:\n",
    "            KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN = \"finder_cmp_object_image_dropdown\"\n",
    "            finder_cmp_object_image_dropdown = wid.Dropdown(\n",
    "                options=object_images_selected_filenames,\n",
    "                value=memoize.get(\n",
    "                    KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN,\n",
    "                    default=object_images_selected_filenames[0],\n",
    "                    possible_values=object_images_selected_filenames,\n",
    "                ),\n",
    "                description=\"Object image\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            finder_cmp_output = wid.Output()\n",
    "            finder_cmp_output_workaround = wid.VBox([])\n",
    "\n",
    "            # Temporary capturing is bugged in vscode\n",
    "            # @finder_cmp_output.capture(\n",
    "            #    clear_output=True, wait=False\n",
    "            # )\n",
    "            def on_finder_cmp_change(change=None):\n",
    "                memoize.set(\n",
    "                    KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN,\n",
    "                    finder_cmp_object_image_dropdown.value,\n",
    "                )\n",
    "\n",
    "                selected_object_image_index = object_images_selected_filenames.index(\n",
    "                    finder_cmp_object_image_dropdown.value\n",
    "                )\n",
    "\n",
    "                selected_object_image_color = object_images_selected[\n",
    "                    selected_object_image_index\n",
    "                ].image_color\n",
    "\n",
    "                selected_object_keypoints = (\n",
    "                    object_recognition_result.detected_objects_keypoints[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                )\n",
    "                selected_scene_keypoints = (\n",
    "                    object_recognition_result.detected_scenes_keypoints[0]\n",
    "                )\n",
    "                selected_matches = object_recognition_result.object_scene_matches[\n",
    "                    selected_object_image_index\n",
    "                ][0]\n",
    "\n",
    "                with LogTimer(\"Displaying sift result\"):\n",
    "                    annotated_image = draw_matches(\n",
    "                        image_1_i=selected_object_image_color,\n",
    "                        keypoints_1=selected_object_keypoints,\n",
    "                        image_2_i=scene_image_selected.image_color,\n",
    "                        keypoints_2=selected_scene_keypoints,\n",
    "                        matches=selected_matches,\n",
    "                    )\n",
    "                    ipy_image = to_ipy_image(\n",
    "                        annotated_image,\n",
    "                        longest_side=image_size * 3,\n",
    "                        upscale=True,\n",
    "                    )\n",
    "                    finder_cmp_output_workaround.children = [ipy_image]\n",
    "                    # sadly bugged on vscode display(ipy_image)\n",
    "\n",
    "            finder_cmp_object_image_dropdown.observe(\n",
    "                on_finder_cmp_change, names=\"value\"\n",
    "            )\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        finder_cmp_object_image_dropdown,\n",
    "                        finder_cmp_output_workaround,\n",
    "                        finder_cmp_output,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_finder_cmp_change()\n",
    "\n",
    "        # RUN RANSAC\n",
    "        KEY_RANSAC_CONFIDENCE_SLIDER = \"ransac_confidence_slider\"\n",
    "        ransac_confidence_slider = wid.FloatSlider(\n",
    "            value=memoize.get(KEY_RANSAC_CONFIDENCE_SLIDER, default=0.85),\n",
    "            min=0.1,\n",
    "            max=0.99,\n",
    "            step=0.01,\n",
    "            continuous_update=False,\n",
    "            orientation=\"horizontal\",\n",
    "            readout=True,\n",
    "            readout_format=\".2f\",\n",
    "            description=\"RANSAC confidence\",\n",
    "            **widgets_styling_slider,\n",
    "        )\n",
    "        KEY_RANSAC_INLIER_THRESHOLD_SLIDER = \"ransac_inlier_threshold_slider\"\n",
    "        ransac_inlier_threshold_slider = wid.FloatSlider(\n",
    "            value=memoize.get(KEY_RANSAC_INLIER_THRESHOLD_SLIDER, default=5.0),\n",
    "            min=0.1,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            continuous_update=False,\n",
    "            orientation=\"horizontal\",\n",
    "            readout=True,\n",
    "            readout_format=\".1f\",\n",
    "            description=\"RANSAC inlier threshold\",\n",
    "            **widgets_styling_slider,\n",
    "        )\n",
    "        ransac_default_button = wid.Button(\n",
    "            description=\"Default RANSAC\",\n",
    "            **widgets_styling,\n",
    "        )\n",
    "        ransac_output = wid.Output()\n",
    "\n",
    "        @ransac_output.capture(clear_output=True, wait=False)\n",
    "        def on_ransac_change(change=None):\n",
    "            memoize.set(KEY_RANSAC_CONFIDENCE_SLIDER, ransac_confidence_slider.value)\n",
    "            memoize.set(\n",
    "                KEY_RANSAC_INLIER_THRESHOLD_SLIDER, ransac_inlier_threshold_slider.value\n",
    "            )\n",
    "\n",
    "            selected_scene_keypoints = (\n",
    "                object_recognition_result.detected_scenes_keypoints[0]\n",
    "            )\n",
    "            selected_objects_keypoints = [\n",
    "                object_recognition_result.detected_objects_keypoints[i]\n",
    "                for i, _ in enumerate(object_images_selected)\n",
    "            ]\n",
    "\n",
    "            selected_objects_matches = [\n",
    "                object_recognition_result.object_scene_matches[i][0]\n",
    "                for i, _ in enumerate(object_images_selected)\n",
    "            ]\n",
    "\n",
    "            with LogTimer(\"Running find homography\"):\n",
    "                homography_results = []\n",
    "                for selected_object_image_index in range(\n",
    "                    len(object_images_selected_indices)\n",
    "                ):\n",
    "                    selected_object_name = object_images_selected_filenames[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "\n",
    "                    selected_object_keypoints = selected_objects_keypoints[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                    selected_matches = selected_objects_matches[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                    # get the target (scene) and source (object) points from the matches\n",
    "                    target_points = np.array(\n",
    "                        [\n",
    "                            selected_scene_keypoints[match.trainIdx].pt\n",
    "                            for match in selected_matches\n",
    "                        ],\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "                    source_points = np.array(\n",
    "                        [\n",
    "                            selected_object_keypoints[match.queryIdx].pt\n",
    "                            for match in selected_matches\n",
    "                        ],\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "\n",
    "                    with LogTimer(\n",
    "                        f\"Calculating homography for object {selected_object_name}\"\n",
    "                    ):\n",
    "                        homography_result = (\n",
    "                            points_of_interest_impl.find_homography_ransac(\n",
    "                                source_points,\n",
    "                                target_points,\n",
    "                                ransac_confidence_slider.value,\n",
    "                                ransac_inlier_threshold_slider.value,\n",
    "                            )\n",
    "                        )\n",
    "                        display(\n",
    "                            f\"Used {homography_result.num_iterations} iterations to find the homography for object {selected_object_name}\"\n",
    "                        )\n",
    "                    homography_results.append(homography_result)\n",
    "\n",
    "            # Display inliers\n",
    "            KEY_SHOW_INLIERS_CHECKBOX = \"show_inliers_checkbox\"\n",
    "            show_inliers_checkbox = wid.Checkbox(\n",
    "                value=memoize.get(KEY_SHOW_INLIERS_CHECKBOX, default=True),\n",
    "                description=\"Show inliers\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN = (\n",
    "                \"show_inliers_object_image_dropdown\"\n",
    "            )\n",
    "\n",
    "            if len(object_images_selected_indices) == 0:\n",
    "                display(\"No object images selected\")\n",
    "                return\n",
    "\n",
    "            show_inliers_object_image_dropdown = wid.Dropdown(\n",
    "                options=object_images_selected_filenames,\n",
    "                value=memoize.get(\n",
    "                    KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN,\n",
    "                    default=object_images_selected_filenames[0],\n",
    "                    possible_values=object_images_selected_filenames,\n",
    "                ),\n",
    "                description=\"Object image\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            show_inlier_output = wid.Output()\n",
    "            show_inlier_output_workaround = wid.VBox([])\n",
    "\n",
    "            # Temporary capturing is bugged in vscode\n",
    "            # @show_inlier_output.capture(\n",
    "            #    clear_output=True, wait=False\n",
    "            # )\n",
    "            def on_show_inliers_change(change=None):\n",
    "                memoize.set(KEY_SHOW_INLIERS_CHECKBOX, show_inliers_checkbox.value)\n",
    "                memoize.set(\n",
    "                    KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN,\n",
    "                    show_inliers_object_image_dropdown.value,\n",
    "                )\n",
    "\n",
    "                if show_inliers_checkbox.value:\n",
    "                    show_inlier_output_workaround.children = [\n",
    "                        show_inliers_object_image_dropdown\n",
    "                    ]\n",
    "\n",
    "                    selected_object_image_index = (\n",
    "                        object_images_selected_filenames.index(\n",
    "                            show_inliers_object_image_dropdown.value\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # get the mask boolean array of inliers\n",
    "                    inliers = homography_results[\n",
    "                        selected_object_image_index\n",
    "                    ].debug_inliers\n",
    "\n",
    "                    debug_chosen_source_points = homography_results[\n",
    "                        selected_object_image_index\n",
    "                    ].debug_chosen_source_points\n",
    "\n",
    "                    if inliers is not None:\n",
    "                        with LogTimer(\"Drawing inliers\"):\n",
    "                            draw_matches_params = {\"matchesMask\": inliers.astype(int)}\n",
    "                            annotated_image = draw_matches(\n",
    "                                image_1_i=object_images_selected[\n",
    "                                    selected_object_image_index\n",
    "                                ].image_color,\n",
    "                                keypoints_1=selected_objects_keypoints[\n",
    "                                    selected_object_image_index\n",
    "                                ],\n",
    "                                image_2_i=scene_image_selected.image_color,\n",
    "                                keypoints_2=selected_scene_keypoints,\n",
    "                                matches=selected_objects_matches[\n",
    "                                    selected_object_image_index\n",
    "                                ],\n",
    "                                params=draw_matches_params,\n",
    "                            )\n",
    "                            if debug_chosen_source_points is not None:\n",
    "                                for source_point in debug_chosen_source_points:\n",
    "                                    cv2.circle(\n",
    "                                        annotated_image,\n",
    "                                        tuple(np.round(source_point).astype(int)),\n",
    "                                        5,\n",
    "                                        (255, 255, 255),\n",
    "                                        -1,\n",
    "                                    )\n",
    "                            ipy_image = to_ipy_image(\n",
    "                                annotated_image,\n",
    "                                longest_side=image_size * 3,\n",
    "                                upscale=True,\n",
    "                            )\n",
    "                            # display(ipy_image)\n",
    "                            show_inlier_output_workaround.children = [\n",
    "                                *show_inlier_output_workaround.children,\n",
    "                                ipy_image,\n",
    "                            ]\n",
    "                else:\n",
    "                    show_inlier_output_workaround.children = []\n",
    "\n",
    "            show_inliers_checkbox.observe(on_show_inliers_change, names=\"value\")\n",
    "            show_inliers_object_image_dropdown.observe(\n",
    "                on_show_inliers_change, names=\"value\"\n",
    "            )\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        show_inliers_checkbox,\n",
    "                        show_inlier_output_workaround,\n",
    "                        show_inlier_output,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_show_inliers_change()\n",
    "\n",
    "            # Display homography results\n",
    "            annotated_scene_image = scene_image_selected.image_color.copy()\n",
    "            annotated_scene_image_overlay = scene_image_selected.image_color.copy()\n",
    "            for i, homography_result in enumerate(homography_results):\n",
    "                if homography_result.homography is None:\n",
    "                    continue\n",
    "\n",
    "                draw_projected_object(\n",
    "                    annotated_scene_image,\n",
    "                    object_images_selected[i].image_color,\n",
    "                    homography_result.homography,\n",
    "                    draw_object=False,\n",
    "                    fill_color=None,\n",
    "                    outline_color=object_colors[i],\n",
    "                )\n",
    "                draw_projected_object(\n",
    "                    annotated_scene_image_overlay,\n",
    "                    object_images_selected[i].image_color,\n",
    "                    homography_result.homography,\n",
    "                    draw_object=True,\n",
    "                    fill_color=None,\n",
    "                    outline_color=object_colors[i],\n",
    "                )\n",
    "            display(\n",
    "                to_ipy_image(\n",
    "                    annotated_scene_image, longest_side=image_size * 3, upscale=True\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                to_ipy_image(\n",
    "                    annotated_scene_image_overlay,\n",
    "                    longest_side=image_size * 3,\n",
    "                    upscale=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        ransac_confidence_slider.observe(on_ransac_change, names=\"value\")\n",
    "        ransac_inlier_threshold_slider.observe(on_ransac_change, names=\"value\")\n",
    "\n",
    "        def default_ransac(change=None):\n",
    "            memoize.delete_keys(\n",
    "                [\n",
    "                    KEY_RANSAC_CONFIDENCE_SLIDER,\n",
    "                    KEY_RANSAC_INLIER_THRESHOLD_SLIDER,\n",
    "                ]\n",
    "            )\n",
    "            on_finder_image_selection_change()\n",
    "\n",
    "        ransac_default_button.on_click(default_ransac)\n",
    "\n",
    "        display(\n",
    "            wid.VBox(\n",
    "                [\n",
    "                    ransac_confidence_slider,\n",
    "                    ransac_inlier_threshold_slider,\n",
    "                    ransac_default_button,\n",
    "                    ransac_output,\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        on_ransac_change()\n",
    "\n",
    "    finder_object_image_select.set_on_selection_change(on_finder_image_selection_change)\n",
    "    finder_scene_image_select.set_on_selection_change(on_finder_image_selection_change)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HTML(\"<h2>Scene images</h2>\"),\n",
    "                        finder_scene_image_select.get_view(),\n",
    "                    ]\n",
    "                ),\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HTML(\"<h2>Object images</h2>\"),\n",
    "                        finder_object_image_select.get_view(),\n",
    "                    ]\n",
    "                ),\n",
    "                finder_image_selection_output,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    on_finder_image_selection_change()\n",
    "\n",
    "\n",
    "finder_image_set_dropdown.observe(on_finder_menu_change, names=\"value\")\n",
    "finder_points_of_interest_impl_dropdown.observe(on_finder_menu_change, names=\"value\")\n",
    "finder_reload_impl_button.on_click(on_finder_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    finder_image_set_dropdown,\n",
    "                    finder_points_of_interest_impl_dropdown,\n",
    "                    finder_reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            finder_output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_finder_menu_change()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
