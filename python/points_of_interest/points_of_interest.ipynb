{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as wid\n",
    "from utils.ipywidgets_extended import (\n",
    "    widgets_styling,\n",
    "    widgets_styling_slider,\n",
    "    MultiSelect,\n",
    "    RadioSelect,\n",
    ")\n",
    "\n",
    "from utils.setup_notebook import init_notebook\n",
    "from utils.setup_logging import setup_logging\n",
    "import utils.memoize as memoize\n",
    "\n",
    "init_notebook()\n",
    "setup_logging(\"INFO\")\n",
    "memoize.set_file_store_path(\"points_of_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numba as nb\n",
    "from numba import cuda\n",
    "import cv2\n",
    "\n",
    "from utils.benchmarking import LogTimer\n",
    "from utils.plotting_tools import (\n",
    "    SmartFigure,\n",
    "    to_ipy_image,\n",
    "    plot_kernel,\n",
    "    plot_matrix,\n",
    ")\n",
    "from utils.image_tools import load_image, LoadedImage\n",
    "import utils.dyn_module as dyn\n",
    "from utils.cv2_tools import draw_keypoints, draw_matches\n",
    "from utils.distinct_colors import bgrs\n",
    "\n",
    "logging.getLogger(\"numba.cuda.cudadrv.driver\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa496563c994b4cb1b5427d861e07d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset memoize store', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset_memoize_store_button = wid.Button(description=\"Reset memoize store\")\n",
    "reset_memoize_store_button.on_click(lambda x: memoize.reset_store())\n",
    "display(reset_memoize_store_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Points of Interest Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-10 17:59:03.266 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 1 modules \u001b[0mstarted \u001b[90m(..\\utils\\dyn_module.py:59)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.276 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading harris_points_of_interest \u001b[0mstarted \u001b[90m(..\\utils\\dyn_module.py:32)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.293 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading harris_points_of_interest \u001b[0mtook: \u001b[34m17.6725 ms\u001b[0m \u001b[90m(..\\utils\\dyn_module.py:32)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.309 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 1 modules \u001b[0mtook: \u001b[34m299.6965 ms\u001b[0m \u001b[90m(..\\utils\\dyn_module.py:59)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dir_points_of_interest_impls = \"./points_of_interest_impls\"\n",
    "points_of_interest_impls_module_names = dyn.load_modules(dir_points_of_interest_impls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Input Image Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-10 17:59:03.416 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_input \u001b[0mstarted \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.433 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.450 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.534 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam.jpg \u001b[0mtook: \u001b[34m70.3901 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.558 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.724 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back.tiff \u001b[0mtook: \u001b[34m169.5325 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.731 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.917 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front.tiff \u001b[0mtook: \u001b[34m172.0131 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:03.934 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.176 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back.tiff \u001b[0mtook: \u001b[34m235.6714 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.193 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.476 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front.tiff \u001b[0mtook: \u001b[34m283.4085 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.493 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.592 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera.jpg \u001b[0mtook: \u001b[34m99.3770 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.623 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.719 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner.tiff \u001b[0mtook: \u001b[34m92.9709 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.746 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.876 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front.tiff \u001b[0mtook: \u001b[34m143.3049 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.876 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.966 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera.jpg \u001b[0mtook: \u001b[34m71.8657 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:04.983 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.167 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera.jpg \u001b[0mtook: \u001b[34m177.1506 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.190 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.387 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner.tiff \u001b[0mtook: \u001b[34m199.5446 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.405 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.609 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front.tiff \u001b[0mtook: \u001b[34m208.7939 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.622 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.843 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back.tiff \u001b[0mtook: \u001b[34m209.4017 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:05.860 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front.tiff \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.075 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front.tiff \u001b[0mtook: \u001b[34m219.6700 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.084 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.409 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1.jpg \u001b[0mtook: \u001b[34m326.9679 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.424 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.819 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2.jpg \u001b[0mtook: \u001b[34m363.7815 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:06.856 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:07.360 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3.jpg \u001b[0mtook: \u001b[34m507.2800 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:07.387 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:07.758 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4.jpg \u001b[0mtook: \u001b[34m361.3613 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:07.776 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:08.222 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5.jpg \u001b[0mtook: \u001b[34m434.8242 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:08.249 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:08.591 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6.jpg \u001b[0mtook: \u001b[34m337.0087 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:08.620 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.050 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7.jpg \u001b[0mtook: \u001b[34m431.1560 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.067 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets \u001b[0mtook: \u001b[31m5.6386 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.083 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.099 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.548 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827.jpg \u001b[0mtook: \u001b[34m445.7167 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:09.563 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:10.135 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828.jpg \u001b[0mtook: \u001b[34m552.3875 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:10.148 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:10.625 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831.jpg \u001b[0mtook: \u001b[34m471.8448 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:10.650 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.172 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833.jpg \u001b[0mtook: \u001b[34m509.7697 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.203 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835.jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.850 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835.jpg \u001b[0mtook: \u001b[34m664.6409 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.877 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office \u001b[0mtook: \u001b[31m2.7800 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.899 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_input \u001b[0mtook: \u001b[31m8.4813 s\u001b[0m \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.927 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_scaled_input \u001b[0mstarted \u001b[90m(notebook_cell:14)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.954 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets_scaled_(618,824) \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:11.976 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam_(291,320).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.013 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_bisasam_(291,320).jpg \u001b[0mtook: \u001b[34m34.2753 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.042 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back_(210,111).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.077 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_back_(210,111).png \u001b[0mtook: \u001b[34m36.3228 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.108 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front_(212,112).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.160 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_choco_front_(212,112).png \u001b[0mtook: \u001b[34m35.8227 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.215 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back_(169,166).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.278 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_back_(169,166).png \u001b[0mtook: \u001b[34m65.8826 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.309 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front_(170,166).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.350 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_green_front_(170,166).png \u001b[0mtook: \u001b[34m45.1158 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.367 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera_(391,433).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.403 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_camera_(391,433).jpg \u001b[0mtook: \u001b[34m29.1372 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.425 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner_(97,110).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.451 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_back_scanner_(97,110).png \u001b[0mtook: \u001b[34m24.8402 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.476 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_(95,108).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.501 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_(95,108).png \u001b[0mtook: \u001b[34m28.5575 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.525 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera_(339,413).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.555 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_manner_front_camera_(339,413).jpg \u001b[0mtook: \u001b[34m35.1960 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.567 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera_(525,580).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.605 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_camera_(525,580).jpg \u001b[0mtook: \u001b[34m28.8909 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.630 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner_(152,169).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.663 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_back_scanner_(152,169).png \u001b[0mtook: \u001b[34m36.3779 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.681 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front_(154,170).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.711 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_red_front_(154,170).png \u001b[0mtook: \u001b[34m25.2528 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.735 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back_(169,167).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.769 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_back_(169,167).png \u001b[0mtook: \u001b[34m31.2169 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.795 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front_(165,166).png \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.834 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading object_yellow_front_(165,166).png \u001b[0mtook: \u001b[34m37.4405 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.849 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.877 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_1_(618,824).jpg \u001b[0mtook: \u001b[34m23.5315 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.898 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.928 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_2_(618,824).jpg \u001b[0mtook: \u001b[34m33.5239 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.947 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:12.984 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_3_(618,824).jpg \u001b[0mtook: \u001b[34m31.2018 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.005 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.044 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_4_(618,824).jpg \u001b[0mtook: \u001b[34m30.0668 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.066 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.105 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_5_(618,824).jpg \u001b[0mtook: \u001b[34m33.7628 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.127 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.163 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_6_(618,824).jpg \u001b[0mtook: \u001b[34m36.8405 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.187 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7_(618,824).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.228 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading scene_7_(618,824).jpg \u001b[0mtook: \u001b[34m44.5435 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.242 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set objects_sweets_scaled_(618,824) \u001b[0mtook: \u001b[31m1.3028 s\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.268 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office_scaled_(604,453) \u001b[0mstarted \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.294 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827_(604,453).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.320 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124827_(604,453).jpg \u001b[0mtook: \u001b[34m26.2412 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.344 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828_(604,453).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.373 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124828_(604,453).jpg \u001b[0mtook: \u001b[34m29.3945 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.384 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831_(604,453).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.418 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124831_(604,453).jpg \u001b[0mtook: \u001b[34m26.9478 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.436 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833_(604,453).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.470 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124833_(604,453).jpg \u001b[0mtook: \u001b[34m29.6180 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.487 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835_(604,453).jpg \u001b[0mstarted \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.516 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading 20241105_124835_(604,453).jpg \u001b[0mtook: \u001b[34m22.8019 ms\u001b[0m \u001b[90m(..\\utils\\image_tools.py:69)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.542 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image set stitch_the_office_scaled_(604,453) \u001b[0mtook: \u001b[34m267.7312 ms\u001b[0m \u001b[90m(notebook_cell:16)\u001b[0m\n",
      "\u001b[90m2024-11-10 17:59:13.562 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mLoading image sets from image_sets_scaled_input \u001b[0mtook: \u001b[31m1.6420 s\u001b[0m \u001b[90m(notebook_cell:14)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_image_set_dir = \"./image_sets_input\"\n",
    "input_image_set_scaled_dir = \"./image_sets_scaled_input\"\n",
    "\n",
    "os.makedirs(input_image_set_dir, exist_ok=True)\n",
    "os.makedirs(input_image_set_scaled_dir, exist_ok=True)\n",
    "\n",
    "input_image_sets = {}\n",
    "\n",
    "\n",
    "def load_image_sets(image_sets_dir: str):\n",
    "    image_sets_folders = os.listdir(image_sets_dir)\n",
    "    image_sets_folders.sort()\n",
    "\n",
    "    with LogTimer(f\"Loading image sets from {Path(image_sets_dir).name}\"):\n",
    "        for image_set_name in image_sets_folders:\n",
    "            with LogTimer(f\"Loading image set {image_set_name}\"):\n",
    "                image_set_dir = os.path.join(image_sets_dir, image_set_name)\n",
    "                image_set = []\n",
    "\n",
    "                images_in_image_set = os.listdir(image_set_dir)\n",
    "                images_in_image_set.sort()\n",
    "\n",
    "                for image_name in images_in_image_set:\n",
    "                    image = load_image(os.path.join(image_set_dir, image_name))\n",
    "                    image_set.append(image)\n",
    "\n",
    "                input_image_sets[image_set_name] = image_set\n",
    "\n",
    "\n",
    "def save_image_set(image_set: list, image_set_dir: str):\n",
    "    os.makedirs(image_set_dir, exist_ok=True)\n",
    "    for image in image_set:\n",
    "        # if not jpg or png set to png\n",
    "        filepath = Path(image.filename)\n",
    "        if filepath.suffix not in [\".jpg\", \".png\"]:\n",
    "            output_filename = filepath.stem + \".png\"\n",
    "        else:\n",
    "            output_filename = filepath.name\n",
    "        cv2.imwrite(os.path.join(image_set_dir, output_filename), image.image_color)\n",
    "\n",
    "\n",
    "load_image_sets(input_image_set_dir)\n",
    "load_image_sets(input_image_set_scaled_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image set scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_image_in_image_set(image_set: list) -> np.array:\n",
    "    largest_image = None\n",
    "    largest_pixel_count = 0\n",
    "    for image in image_set:\n",
    "        resolution = image.image_color.shape[:2]\n",
    "        pixel_count = resolution[0] * resolution[1]\n",
    "        if pixel_count > largest_pixel_count:\n",
    "            largest_pixel_count = pixel_count\n",
    "            largest_image = image\n",
    "    return largest_image\n",
    "\n",
    "\n",
    "def get_largest_resolution_in_image_set(image_set: list) -> tuple:\n",
    "    largest_image = get_largest_image_in_image_set(image_set)\n",
    "    return largest_image.image_color.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6c6e1104444cd5bcfeb728dc8224fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', layout=Layout(width='max-content'), options=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scaler():\n",
    "    clear_output()\n",
    "    KEY_SCALER_IMAGE_SET_DROPDOWN = \"scaler_image_set_dropdown\"\n",
    "    scaler_image_set_dropdown = wid.Dropdown(\n",
    "        options=list(input_image_sets.keys()),\n",
    "        value=memoize.get(\n",
    "            KEY_SCALER_IMAGE_SET_DROPDOWN,\n",
    "            default=next(iter(input_image_sets.keys())),\n",
    "            possible_values=input_image_sets.keys(),\n",
    "        ),\n",
    "        description=\"Image set\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "    scaler_largest_resolution_label = wid.Label(\"Largest image: (X,X)\")\n",
    "    KEY_SCALER_SCALE_SLIDER = \"scaler_scale_slider\"\n",
    "    scaler_scale_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SCALER_SCALE_SLIDER, default=1.0),\n",
    "        min=0.1,\n",
    "        max=30.0,\n",
    "        step=0.1,\n",
    "        continuous_update=True,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Scale\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    scaler_result_resolution_label = wid.Label(\"Resulting largest image: (X,X)\")\n",
    "    scaler_create_scaled_image_set_button = wid.Button(\n",
    "        description=\"Create scaled image set\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "\n",
    "    def on_update_resolution_labels(change=None):\n",
    "        memoize.set(KEY_SCALER_IMAGE_SET_DROPDOWN, scaler_image_set_dropdown.value)\n",
    "        memoize.set(KEY_SCALER_SCALE_SLIDER, scaler_scale_slider.value)\n",
    "\n",
    "        image_set = input_image_sets[scaler_image_set_dropdown.value]\n",
    "        largest_image = get_largest_image_in_image_set(image_set)\n",
    "        largest_resolution = largest_image.image_color.shape[:2]\n",
    "        scaler_largest_resolution_label.value = f\"Largest image: {largest_resolution}\"\n",
    "        scaler_result_resolution_label.value = f\"Resulting largest image: {tuple(int(x * 1/scaler_scale_slider.value) for x in largest_resolution)}\"\n",
    "\n",
    "    scaler_scale_slider.observe(on_update_resolution_labels, names=\"value\")\n",
    "    scaler_image_set_dropdown.observe(on_update_resolution_labels, names=\"value\")\n",
    "    on_update_resolution_labels()\n",
    "\n",
    "    def create_scaled_image_set(change=None):\n",
    "        with LogTimer(\n",
    "            f\"Creating scaled image set for {scaler_image_set_dropdown.value}\"\n",
    "        ):\n",
    "            original_image_set = input_image_sets[scaler_image_set_dropdown.value]\n",
    "\n",
    "            scale = 1 / scaler_scale_slider.value\n",
    "\n",
    "            largest_resolution = get_largest_resolution_in_image_set(original_image_set)\n",
    "            scaled_resolution = tuple(int(x * scale) for x in largest_resolution)\n",
    "            scaled_resolution_fs_string = (\n",
    "                f\"({scaled_resolution[0]},{scaled_resolution[1]})\"\n",
    "            )\n",
    "\n",
    "            scaled_image_set_name = f\"{scaler_image_set_dropdown.value}_scaled_{scaled_resolution_fs_string}\"\n",
    "\n",
    "            scaled_image_set_dir = os.path.join(\n",
    "                input_image_set_scaled_dir, scaled_image_set_name\n",
    "            )\n",
    "\n",
    "            new_image_set = []\n",
    "            for image in original_image_set:\n",
    "                scaled_resolution = tuple(\n",
    "                    int(x * scale) for x in image.image_color.shape[:2]\n",
    "                )\n",
    "                scaled_resolution_fs_string = (\n",
    "                    f\"({scaled_resolution[0]},{scaled_resolution[1]})\"\n",
    "                )\n",
    "                with LogTimer(\n",
    "                    f\"Resizing image {image.filename} from {image.image_color.shape[:2]} to {scaled_resolution}\"\n",
    "                ):\n",
    "                    new_image = LoadedImage()\n",
    "                    new_image.image_color = cv2.resize(\n",
    "                        image.image_color, (scaled_resolution[1], scaled_resolution[0])\n",
    "                    )\n",
    "                    new_image.filename = f\"{Path(image.filename).stem}_{scaled_resolution_fs_string}{Path(image.filename).suffix}\"\n",
    "                    new_image_set.append(new_image)\n",
    "\n",
    "            save_image_set(new_image_set, scaled_image_set_dir)\n",
    "            load_image_sets(input_image_set_scaled_dir)\n",
    "            scaler()\n",
    "\n",
    "    scaler_create_scaled_image_set_button.on_click(create_scaled_image_set)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                wid.HBox([scaler_image_set_dropdown, scaler_largest_resolution_label]),\n",
    "                wid.HBox([scaler_scale_slider, scaler_result_resolution_label]),\n",
    "                scaler_create_scaled_image_set_button,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "scaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Harris Points of Interest detection and Image stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8731554453c4b82ab0f8ab47dbfabe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', index=1, layout=Layout(width='max-content'), o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_width = 16\n",
    "image_size = 512\n",
    "\n",
    "# filter keys by \"stitch\"\n",
    "input_image_sets_stitch = {\n",
    "    key: value for key, value in input_image_sets.items() if \"stitch\" in key\n",
    "}\n",
    "\n",
    "KEY_IMAGE_SET_DROPDOWN = \"image_set_dropdown\"\n",
    "image_set_dropdown = wid.Dropdown(\n",
    "    options=list(input_image_sets_stitch.keys()),\n",
    "    value=memoize.get(\n",
    "        KEY_IMAGE_SET_DROPDOWN,\n",
    "        default=next(iter(input_image_sets_stitch.keys())),\n",
    "        possible_values=input_image_sets_stitch.keys(),\n",
    "    ),\n",
    "    description=\"Image set\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN = \"points_of_interest_impl_dropdown\"\n",
    "points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "output = wid.Output()\n",
    "\n",
    "\n",
    "@output.capture(clear_output=True, wait=True)\n",
    "def on_menu_change(change=None):\n",
    "    memoize.set(KEY_IMAGE_SET_DROPDOWN, image_set_dropdown.value)\n",
    "    memoize.set(\n",
    "        KEY_POINTS_OF_INTEREST_IMPL_DROPDOWN, points_of_interest_impl_dropdown.value\n",
    "    )\n",
    "\n",
    "    # reload the impl module\n",
    "    current_points_of_interest_impl = points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(current_points_of_interest_impl)\n",
    "\n",
    "    input_image_set = input_image_sets_stitch[image_set_dropdown.value]\n",
    "    total_image_count = len(input_image_set)\n",
    "    KEY_IMAGE_COUNT_SLIDER = f\"image_count_slider_{image_set_dropdown.value}\"\n",
    "    current_image_count_slider_value = memoize.get(\n",
    "        KEY_IMAGE_COUNT_SLIDER, default=total_image_count\n",
    "    )\n",
    "    if current_image_count_slider_value > total_image_count:\n",
    "        current_image_count_slider_value = total_image_count\n",
    "    image_count_slider = wid.IntSlider(\n",
    "        value=current_image_count_slider_value,\n",
    "        min=1,\n",
    "        max=total_image_count,\n",
    "        step=1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\"d\",\n",
    "        description=\"Image count\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "\n",
    "    def on_image_count_slider_change(change=None):\n",
    "        memoize.set(KEY_IMAGE_COUNT_SLIDER, image_count_slider.value)\n",
    "        on_menu_change()\n",
    "\n",
    "    image_count_slider.observe(on_image_count_slider_change, names=\"value\")\n",
    "    display(image_count_slider)\n",
    "\n",
    "    image_set = input_image_set[: image_count_slider.value]\n",
    "\n",
    "    with LogTimer(\"Displaying input images\"):\n",
    "        input_ipy_images_color = [\n",
    "            to_ipy_image(image.image_color, longest_side=image_size, upscale=True)\n",
    "            for image in image_set\n",
    "        ]\n",
    "        display(wid.HBox(input_ipy_images_color))\n",
    "        input_ipy_images_gray = [\n",
    "            to_ipy_image(image.image_gray, longest_side=image_size, upscale=True)\n",
    "            for image in image_set\n",
    "        ]\n",
    "        display(wid.HBox(input_ipy_images_gray))\n",
    "\n",
    "    KEY_SIGMA1_SLIDER = \"sigma1_slider\"\n",
    "    sigma1_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SIGMA1_SLIDER, default=0.8),\n",
    "        min=0.1,\n",
    "        max=20.0,\n",
    "        step=0.1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Sigma 1\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_SIGMA2_SLIDER = \"sigma2_slider\"\n",
    "    sigma2_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_SIGMA2_SLIDER, default=1.5),\n",
    "        min=0.1,\n",
    "        max=20.0,\n",
    "        step=0.1,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".1f\",\n",
    "        description=\"Sigma 2\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_THRESHOLD_SLIDER = \"threshold_slider\"\n",
    "    threshold_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_THRESHOLD_SLIDER, default=0.01),\n",
    "        min=0.0,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".2f\",\n",
    "        description=\"Threshold\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    KEY_HARRIS_K_SLIDER = \"harris_k_slider\"\n",
    "    harris_k_slider = wid.FloatSlider(\n",
    "        value=memoize.get(KEY_HARRIS_K_SLIDER, default=0.04),\n",
    "        min=0.01,\n",
    "        max=0.1,\n",
    "        step=0.01,\n",
    "        continuous_update=False,\n",
    "        orientation=\"horizontal\",\n",
    "        readout=True,\n",
    "        readout_format=\".2f\",\n",
    "        description=\"Harris k\",\n",
    "        **widgets_styling_slider,\n",
    "    )\n",
    "    default_harris_button = wid.Button(\n",
    "        description=\"Default Harris\",\n",
    "        **widgets_styling,\n",
    "    )\n",
    "    output_harris_corner = wid.Output()\n",
    "\n",
    "    @output_harris_corner.capture(clear_output=True, wait=True)\n",
    "    def on_harris_change(config=None):\n",
    "        memoize.set(KEY_SIGMA1_SLIDER, sigma1_slider.value)\n",
    "        memoize.set(KEY_SIGMA2_SLIDER, sigma2_slider.value)\n",
    "        memoize.set(KEY_THRESHOLD_SLIDER, threshold_slider.value)\n",
    "        memoize.set(KEY_HARRIS_K_SLIDER, harris_k_slider.value)\n",
    "\n",
    "        image_gray_array = np.stack([image.image_gray for image in image_set])\n",
    "        image_color_array = np.stack([image.image_color for image in image_set])\n",
    "\n",
    "        with LogTimer(\"Calculating Harris corners\"):\n",
    "            harris_corner_keystones = points_of_interest_impl.harris_corner(\n",
    "                image_gray_array,\n",
    "                sigma1_slider.value,\n",
    "                sigma2_slider.value,\n",
    "                harris_k_slider.value,\n",
    "                threshold_slider.value,\n",
    "            )\n",
    "\n",
    "        with LogTimer(\"Displaying Harris corners\"):\n",
    "            annotated_harris_ipy_images = []\n",
    "            for image_idx, image in enumerate(image_set):\n",
    "                keypoint_size = int(max(image.image_color.shape[:2]) / 512)\n",
    "                for keypoint in harris_corner_keystones[image_idx]:\n",
    "                    keypoint.size *= keypoint_size\n",
    "\n",
    "                annotated_image = draw_keypoints(\n",
    "                    image_color_array[image_idx],\n",
    "                    harris_corner_keystones[image_idx],\n",
    "                )\n",
    "                annotated_harris_ipy_images.append(\n",
    "                    wid.VBox(\n",
    "                        [\n",
    "                            wid.Label(f\"{image.filename}\"),\n",
    "                            wid.Label(\n",
    "                                f\"Found {len(harris_corner_keystones[image_idx])} Harris corners\"\n",
    "                            ),\n",
    "                            to_ipy_image(\n",
    "                                annotated_image, longest_side=image_size, upscale=True\n",
    "                            ),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            display(wid.HTML(\"<h2>Harris corners</h2>\"))\n",
    "            display(wid.HBox(annotated_harris_ipy_images))\n",
    "\n",
    "            if total_image_count < 2:\n",
    "                display(wid.HTML(\"<h2>Not enough images to calculate matches</h2>\"))\n",
    "                return\n",
    "            # Flann based matcher\n",
    "            display(wid.HTML(\"<h2>Flann matches</h2>\"))\n",
    "            KEY_FLANN_IMAGE_1_DROPDOWN = \"flann_image_1_dropdown\"\n",
    "            flann_image_1_dropdown = wid.Dropdown(\n",
    "                options=[image.filename for image in image_set],\n",
    "                value=memoize.get(\n",
    "                    KEY_FLANN_IMAGE_1_DROPDOWN,\n",
    "                    default=image_set[0].filename,\n",
    "                    possible_values=[image.filename for image in image_set],\n",
    "                ),\n",
    "                description=\"Image 1\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_FLANN_IMAGE_2_DROPDOWN = \"flann_image_2_dropdown\"\n",
    "            flann_image_2_dropdown = wid.Dropdown(\n",
    "                options=[image.filename for image in image_set],\n",
    "                value=memoize.get(\n",
    "                    KEY_FLANN_IMAGE_2_DROPDOWN,\n",
    "                    default=image_set[1].filename,\n",
    "                    possible_values=[image.filename for image in image_set],\n",
    "                ),\n",
    "                description=\"Image 2\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_PATCH_SIZE_SLIDER = \"patch_size_slider\"\n",
    "            patch_size_slider = wid.IntSlider(\n",
    "                value=memoize.get(KEY_PATCH_SIZE_SLIDER, default=5),\n",
    "                min=1,\n",
    "                max=15,\n",
    "                step=1,\n",
    "                continuous_update=False,\n",
    "                orientation=\"horizontal\",\n",
    "                readout=True,\n",
    "                readout_format=\"d\",\n",
    "                description=\"Patch size\",\n",
    "                **widgets_styling_slider,\n",
    "            )\n",
    "            default_flann_button = wid.Button(\n",
    "                description=\"Default flann values\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            output_flann = wid.Output()\n",
    "\n",
    "            @output_flann.capture(clear_output=True, wait=True)\n",
    "            def on_flann_change(config=None):\n",
    "                memoize.set(KEY_FLANN_IMAGE_1_DROPDOWN, flann_image_1_dropdown.value)\n",
    "                memoize.set(KEY_FLANN_IMAGE_2_DROPDOWN, flann_image_2_dropdown.value)\n",
    "                memoize.set(KEY_PATCH_SIZE_SLIDER, patch_size_slider.value)\n",
    "\n",
    "                image_1_idx = [image.filename for image in image_set].index(\n",
    "                    flann_image_1_dropdown.value\n",
    "                )\n",
    "                image_2_idx = [image.filename for image in image_set].index(\n",
    "                    flann_image_2_dropdown.value\n",
    "                )\n",
    "\n",
    "                image_gray_1 = image_gray_array[image_1_idx]\n",
    "                image_gray_2 = image_gray_array[image_2_idx]\n",
    "\n",
    "                keypoints_1 = harris_corner_keystones[image_1_idx]\n",
    "                keypoints_2 = harris_corner_keystones[image_2_idx]\n",
    "\n",
    "                with LogTimer(\"Compute Descriptors\"):\n",
    "                    filtered_keypoints_1, descriptors_1 = (\n",
    "                        points_of_interest_impl.compute_descriptors(\n",
    "                            image_gray_1, keypoints_1, patch_size_slider.value\n",
    "                        )\n",
    "                    )\n",
    "                    filtered_keypoints_2, descriptors_2 = (\n",
    "                        points_of_interest_impl.compute_descriptors(\n",
    "                            image_gray_2, keypoints_2, patch_size_slider.value\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Calculating Flann matches\"):\n",
    "                    matches = points_of_interest_impl.flann_matches(\n",
    "                        descriptors_1, descriptors_2\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Filtering Flann matches\"):\n",
    "                    matches_filtered = points_of_interest_impl.filter_matches(matches)\n",
    "\n",
    "                display(\n",
    "                    f\"Found {len(matches)} matches. These were filtered down to {len(matches_filtered)} matches ({len(matches_filtered)/len(matches)*100:.2f}%)\"\n",
    "                )\n",
    "\n",
    "                with LogTimer(\"Drawing Flann matches\"):\n",
    "                    draw_matches_image = draw_matches(\n",
    "                        image_color_array[image_1_idx],\n",
    "                        filtered_keypoints_1,\n",
    "                        image_color_array[image_2_idx],\n",
    "                        filtered_keypoints_2,\n",
    "                        matches_filtered,\n",
    "                    )\n",
    "\n",
    "                with LogTimer(\"Displaying Flann matches\"):\n",
    "                    display(\n",
    "                        to_ipy_image(\n",
    "                            draw_matches_image,\n",
    "                            longest_side=image_size * 3,\n",
    "                            upscale=True,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            flann_image_1_dropdown.observe(on_flann_change, names=\"value\")\n",
    "            flann_image_2_dropdown.observe(on_flann_change, names=\"value\")\n",
    "            patch_size_slider.observe(on_flann_change, names=\"value\")\n",
    "\n",
    "            def default_flann(change=None):\n",
    "                memoize.delete_keys(\n",
    "                    [\n",
    "                        KEY_FLANN_IMAGE_1_DROPDOWN,\n",
    "                        KEY_FLANN_IMAGE_2_DROPDOWN,\n",
    "                        KEY_PATCH_SIZE_SLIDER,\n",
    "                    ]\n",
    "                )\n",
    "                on_menu_change()\n",
    "\n",
    "            default_flann_button.on_click(default_flann)\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HBox([flann_image_1_dropdown, flann_image_2_dropdown]),\n",
    "                        wid.HBox([patch_size_slider, default_flann_button]),\n",
    "                        output_flann,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_flann_change()\n",
    "\n",
    "    sigma1_slider.observe(on_harris_change, names=\"value\")\n",
    "    sigma2_slider.observe(on_harris_change, names=\"value\")\n",
    "    threshold_slider.observe(on_harris_change, names=\"value\")\n",
    "    harris_k_slider.observe(on_harris_change, names=\"value\")\n",
    "\n",
    "    def default_harris(change=None):\n",
    "        memoize.delete_keys(\n",
    "            [\n",
    "                KEY_SIGMA1_SLIDER,\n",
    "                KEY_SIGMA2_SLIDER,\n",
    "                KEY_THRESHOLD_SLIDER,\n",
    "                KEY_HARRIS_K_SLIDER,\n",
    "            ]\n",
    "        )\n",
    "        on_menu_change()\n",
    "\n",
    "    default_harris_button.on_click(default_harris)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                sigma1_slider,\n",
    "                sigma2_slider,\n",
    "                threshold_slider,\n",
    "                harris_k_slider,\n",
    "                default_harris_button,\n",
    "                output_harris_corner,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    on_harris_change()\n",
    "\n",
    "\n",
    "image_set_dropdown.observe(on_menu_change, names=\"value\")\n",
    "points_of_interest_impl_dropdown.observe(on_menu_change, names=\"value\")\n",
    "reload_impl_button.on_click(on_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    image_set_dropdown,\n",
    "                    points_of_interest_impl_dropdown,\n",
    "                    reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_menu_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Homography Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f1807cd93646ee96b9e1ce2f4b5321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Point of interest implementation', layout=Layout(width='ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Allow other homography implementations to be selected\n",
    "\n",
    "KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN = (\n",
    "    \"homography_d_points_of_interest_impl_dropdown\"\n",
    ")\n",
    "homography_d_points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_HOMOGRAPHY_D_USE_SVD_CHECKBOX = \"homography_d_use_svd_checkbox\"\n",
    "homography_d_use_svd_checkbox = wid.Checkbox(\n",
    "    value=memoize.get(KEY_HOMOGRAPHY_D_USE_SVD_CHECKBOX, default=True),\n",
    "    description=\"Use SVD\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "homography_d_reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "homography_d_output = wid.Output()\n",
    "\n",
    "color_magenta = tuple([int(x / 2) for x in (255, 0, 255)])\n",
    "\n",
    "\n",
    "def draw_center_lines(image_io: np.ndarray) -> np.ndarray:\n",
    "    height, width = image_io.shape[:2]\n",
    "    cv2.line(image_io, (width // 2, 0), (width // 2, height), (255, 0, 0), 2)\n",
    "    cv2.line(image_io, (0, height // 2), (width, height // 2), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "def image_to_verts(image_i: np.ndarray) -> np.ndarray:\n",
    "    height, width = image_i.shape[:2]\n",
    "    return np.array(\n",
    "        [\n",
    "            [0, 0],\n",
    "            [width, 0],\n",
    "            [width, height],\n",
    "            [0, height],\n",
    "        ],\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_verts(\n",
    "    image_io: np.ndarray,\n",
    "    verts_i: np.ndarray,\n",
    "    thickness=10,\n",
    "    fill_color=None,\n",
    "    outline_color=None,\n",
    ") -> np.ndarray:\n",
    "    if fill_color is not None:\n",
    "        cv2.fillPoly(image_io, [verts_i], fill_color)\n",
    "    if outline_color is None:\n",
    "        line_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]\n",
    "    else:\n",
    "        line_colors = [outline_color] * 4\n",
    "    for i in range(4):\n",
    "        cv2.line(\n",
    "            image_io,\n",
    "            tuple(verts_i[i]),\n",
    "            tuple(verts_i[(i + 1) % 4]),\n",
    "            color=line_colors[i],\n",
    "            thickness=thickness,\n",
    "        )\n",
    "\n",
    "\n",
    "def random_rectangle_transform(\n",
    "    image_i: np.ndarray, rectangle_verts_i: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create a random rectangle in the image and return its vertices in the image and in the object space.\n",
    "\n",
    "    :return: (generated_image, target_points, source_points):\n",
    "        generated_image: image with a single projected rectangle\n",
    "        target_points: array of keypoints_1 in the target image in the shape (n, 2)\n",
    "        source_points: array of keypoints_1 in the source image in the shape (n, 2)\n",
    "    :rtype: (np.ndarray, np.ndarray, np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    image_height, image_width = image_i.shape[:2]\n",
    "\n",
    "    # Compute the height and width of the rectangle from its vertices\n",
    "    min_coords = np.min(rectangle_verts_i, axis=0)\n",
    "    max_coords = np.max(rectangle_verts_i, axis=0)\n",
    "    rect_width = max_coords[0] - min_coords[0]\n",
    "    rect_height = max_coords[1] - min_coords[1]\n",
    "\n",
    "    # Move the rectangle to the center of the scene\n",
    "    image_rectangle_verts = (\n",
    "        rectangle_verts_i\n",
    "        + [\n",
    "            image_width / 2.0 - rect_width / 2.0,\n",
    "            image_height / 2.0 - rect_height / 2.0,\n",
    "        ]\n",
    "        + np.around(10 * np.random.randn(4, 2))\n",
    "    )\n",
    "    image_rectangle_verts = image_rectangle_verts.astype(np.int32)\n",
    "\n",
    "    return image_rectangle_verts\n",
    "\n",
    "\n",
    "def draw_projected_object(\n",
    "    image_io: np.ndarray,\n",
    "    object_image_i: np.ndarray,\n",
    "    homography_i: np.ndarray,\n",
    "    draw_object=True,\n",
    "    fill_color=color_magenta,\n",
    "    outline_color=None,\n",
    ") -> np.ndarray:\n",
    "    # Get the vertices of the object image\n",
    "    object_verts_i = image_to_verts(object_image_i).astype(np.float32)\n",
    "\n",
    "    # Project the object image to the input image\n",
    "    # We have to reshape because openCV expects batched input\n",
    "    projected_verts_i = (\n",
    "        cv2.perspectiveTransform(object_verts_i.reshape(1, -1, 2), homography_i)\n",
    "        .reshape(-1, 2)\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "\n",
    "    draw_verts(\n",
    "        image_io,\n",
    "        projected_verts_i,\n",
    "        thickness=2,\n",
    "        fill_color=fill_color,\n",
    "        outline_color=outline_color,\n",
    "    )\n",
    "\n",
    "    if draw_object:\n",
    "        # Draw the object image in the projected position\n",
    "        object_image_p = cv2.warpPerspective(\n",
    "            object_image_i,\n",
    "            homography_i,\n",
    "            (image_io.shape[1], image_io.shape[0]),\n",
    "        )\n",
    "\n",
    "        cv2.copyTo(src=object_image_p, mask=object_image_p, dst=image_io)\n",
    "\n",
    "\n",
    "@homography_d_output.capture(clear_output=True, wait=True)\n",
    "def on_homography_d_menu_change(change=None):\n",
    "    memoize.set(\n",
    "        KEY_HOMOGRAPHY_D_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        homography_d_points_of_interest_impl_dropdown.value,\n",
    "    )\n",
    "    impl_name = homography_d_points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(impl_name)\n",
    "\n",
    "    test_scene_image_height, test_scene_width = 320, 480\n",
    "    test_scene_image = np.zeros(\n",
    "        shape=(test_scene_image_height, test_scene_width, 3),\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "\n",
    "    object_image = np.full(\n",
    "        shape=(120, 200, 3), dtype=np.uint8, fill_value=color_magenta\n",
    "    )\n",
    "    draw_center_lines(object_image)\n",
    "    object_verts = image_to_verts(object_image)\n",
    "\n",
    "    # draw_center_lines(test_scene_image)\n",
    "\n",
    "    image_rectangle_verts = random_rectangle_transform(test_scene_image, object_verts)\n",
    "    draw_verts(test_scene_image, image_rectangle_verts)\n",
    "\n",
    "    display(to_ipy_image(test_scene_image, longest_side=image_size, upscale=True))\n",
    "\n",
    "    with LogTimer(\"Calculating homography\"):\n",
    "        homography = points_of_interest_impl.find_homography_eq(\n",
    "            object_verts,\n",
    "            image_rectangle_verts,\n",
    "            use_svd=homography_d_use_svd_checkbox.value,\n",
    "        ).homography\n",
    "\n",
    "    draw_projected_object(test_scene_image, object_image, homography)\n",
    "    display(to_ipy_image(test_scene_image, longest_side=image_size, upscale=True))\n",
    "\n",
    "\n",
    "homography_d_points_of_interest_impl_dropdown.observe(\n",
    "    on_homography_d_menu_change, names=\"value\"\n",
    ")\n",
    "homography_d_use_svd_checkbox.observe(on_homography_d_menu_change, names=\"value\")\n",
    "homography_d_reload_impl_button.on_click(on_homography_d_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    homography_d_points_of_interest_impl_dropdown,\n",
    "                    homography_d_use_svd_checkbox,\n",
    "                    homography_d_reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            homography_d_output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_homography_d_menu_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find objects using RANSAC and SIFT and Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f554a95f8b42456c990a60e4588c9a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Image set', index=1, layout=Layout(width='max-content'), o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-10 18:04:06.204 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDisplaying sift result \u001b[0mstarted \u001b[90m(notebook_cell:210)\u001b[0m\n",
      "\u001b[90m2024-11-10 18:04:06.553 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDisplaying sift result \u001b[0mtook: \u001b[34m365.3461 ms\u001b[0m \u001b[90m(notebook_cell:210)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2024-11-10 18:05:12.229 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDrawing inliers \u001b[0mstarted \u001b[90m(notebook_cell:395)\u001b[0m\n",
      "\u001b[90m2024-11-10 18:05:12.581 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDrawing inliers \u001b[0mtook: \u001b[34m345.1622 ms\u001b[0m \u001b[90m(notebook_cell:395)\u001b[0m\n",
      "\u001b[90m2024-11-10 18:05:44.141 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDisplaying sift result \u001b[0mstarted \u001b[90m(notebook_cell:210)\u001b[0m\n",
      "\u001b[90m2024-11-10 18:05:44.452 \u001b[32m\u001b[49mINFO root \u001b[0m\u001b[30mDisplaying sift result \u001b[0mtook: \u001b[34m303.7845 ms\u001b[0m \u001b[90m(notebook_cell:210)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# filter keys by \"objects\"\n",
    "input_image_sets_objects = {\n",
    "    key: value for key, value in input_image_sets.items() if \"objects\" in key\n",
    "}\n",
    "\n",
    "KEY_FINDER_IMAGE_SET_DROPDOWN = \"finder_image_set_dropdown\"\n",
    "finder_image_set_dropdown = wid.Dropdown(\n",
    "    options=list(input_image_sets_objects.keys()),\n",
    "    value=memoize.get(\n",
    "        KEY_FINDER_IMAGE_SET_DROPDOWN,\n",
    "        default=next(iter(input_image_sets_objects.keys())),\n",
    "        possible_values=input_image_sets_objects.keys(),\n",
    "    ),\n",
    "    description=\"Image set\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN = \"finder_points_of_interest_impl_dropdown\"\n",
    "finder_points_of_interest_impl_dropdown = wid.Dropdown(\n",
    "    options=points_of_interest_impls_module_names,\n",
    "    value=memoize.get(\n",
    "        KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        default=points_of_interest_impls_module_names[0],\n",
    "        possible_values=points_of_interest_impls_module_names,\n",
    "    ),\n",
    "    description=\"Point of interest implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "finder_reload_impl_button = wid.Button(\n",
    "    description=\"Reload Implementation\",\n",
    "    **widgets_styling,\n",
    ")\n",
    "finder_output = wid.Output()\n",
    "\n",
    "\n",
    "@finder_output.capture(clear_output=True, wait=False)\n",
    "def on_finder_menu_change(change=None):\n",
    "    memoize.set(KEY_FINDER_IMAGE_SET_DROPDOWN, finder_image_set_dropdown.value)\n",
    "    memoize.set(\n",
    "        KEY_FINDER_POINTS_OF_INTEREST_IMPL_DROPDOWN,\n",
    "        finder_points_of_interest_impl_dropdown.value,\n",
    "    )\n",
    "\n",
    "    # reload the impl module\n",
    "    current_points_of_interest_impl = finder_points_of_interest_impl_dropdown.value\n",
    "    points_of_interest_impl = dyn.load_module(current_points_of_interest_impl)\n",
    "\n",
    "    color_it = bgrs()\n",
    "\n",
    "    # extract scene images from the set\n",
    "    with LogTimer(\"Loading scene images\"):\n",
    "        scene_images = [\n",
    "            image\n",
    "            for image in input_image_sets_objects[finder_image_set_dropdown.value]\n",
    "            if \"scene\" in image.filename\n",
    "        ]\n",
    "        scene_image_wids = [\n",
    "            to_ipy_image(\n",
    "                image.image_color,\n",
    "                longest_side=image_size / 3,\n",
    "                upscale=True,\n",
    "                set_dimensions=True,\n",
    "            )\n",
    "            for image in scene_images\n",
    "        ]\n",
    "        scene_images_filenames = [image.filename for image in scene_images]\n",
    "\n",
    "    KEY_FINDER_SCENE_IMAGE_SELECT = \"finder_scene_image_select\"\n",
    "    finder_scene_image_select = RadioSelect(\n",
    "        all_choices=scene_images_filenames,\n",
    "        default_choice=memoize.get(\n",
    "            KEY_FINDER_SCENE_IMAGE_SELECT,\n",
    "            default=scene_images_filenames[0],\n",
    "            possible_values=scene_images_filenames,\n",
    "        ),\n",
    "        custom_widgets=scene_image_wids,\n",
    "        grid_template_columns=\"1fr 1fr 1fr 1fr 1fr\",\n",
    "    )\n",
    "\n",
    "    # extract object images from the set\n",
    "    with LogTimer(\"Loading object images\"):\n",
    "        object_images = [\n",
    "            image\n",
    "            for image in input_image_sets_objects[finder_image_set_dropdown.value]\n",
    "            if \"object\" in image.filename\n",
    "        ]\n",
    "        object_colors = [next(color_it) for _ in object_images]\n",
    "        # multiply the color by 255 to get the color in the range 0-255\n",
    "        object_colors = [\n",
    "            (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)) for x in object_colors\n",
    "        ]\n",
    "        border_width = 10\n",
    "        framed_object_images = [\n",
    "            cv2.copyMakeBorder(\n",
    "                image.image_color,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                border_width,\n",
    "                cv2.BORDER_CONSTANT,\n",
    "                value=color,\n",
    "            )\n",
    "            for image, color in zip(object_images, object_colors)\n",
    "        ]\n",
    "        object_image_wids = [\n",
    "            to_ipy_image(\n",
    "                image,\n",
    "                longest_side=image_size / 3,\n",
    "                upscale=True,\n",
    "                set_dimensions=True,\n",
    "            )\n",
    "            for image in framed_object_images\n",
    "        ]\n",
    "        object_images_filenames = [image.filename for image in object_images]\n",
    "\n",
    "    KEY_FINDER_OBJECT_IMAGE_SELECT = \"finder_object_image_select1\"\n",
    "    finder_object_image_select = MultiSelect(\n",
    "        all_choices=object_images_filenames,\n",
    "        default_choices=memoize.get(\n",
    "            KEY_FINDER_OBJECT_IMAGE_SELECT,\n",
    "            default=object_images_filenames,\n",
    "            possible_values=object_images_filenames,\n",
    "            multi_value=True,\n",
    "        ),\n",
    "        custom_widgets=object_image_wids,\n",
    "        grid_template_columns=\"1fr 1fr 1fr 1fr 1fr\",\n",
    "    )\n",
    "\n",
    "    finder_image_selection_output = wid.Output()\n",
    "\n",
    "    @finder_image_selection_output.capture(clear_output=True, wait=False)\n",
    "    def on_finder_image_selection_change(change=None):\n",
    "        memoize.set(\n",
    "            KEY_FINDER_OBJECT_IMAGE_SELECT, finder_object_image_select.get_selected()\n",
    "        )\n",
    "        memoize.set(\n",
    "            KEY_FINDER_SCENE_IMAGE_SELECT, finder_scene_image_select.get_selected()\n",
    "        )\n",
    "\n",
    "        scene_image_selected = scene_images[\n",
    "            scene_images_filenames.index(finder_scene_image_select.get_selected())\n",
    "        ]\n",
    "        scene_image_selected_gray = scene_image_selected.image_gray\n",
    "\n",
    "        object_images_selected_indices = [\n",
    "            object_images_filenames.index(filename)\n",
    "            for filename in finder_object_image_select.get_selected()\n",
    "        ]\n",
    "        object_images_selected = [\n",
    "            object_images[index] for index in object_images_selected_indices\n",
    "        ]\n",
    "        object_images_selected_gray = [\n",
    "            image.image_gray for image in object_images_selected\n",
    "        ]\n",
    "\n",
    "        with LogTimer(\"Running sift\"):\n",
    "            object_recognition_result = points_of_interest_impl.run_object_recognition(\n",
    "                object_images_selected_gray, [scene_image_selected_gray]\n",
    "            )\n",
    "\n",
    "        object_images_selected_filenames = [\n",
    "            image.filename for image in object_images_selected\n",
    "        ]\n",
    "\n",
    "        # Show the sift result\n",
    "        if len(object_images_selected) != 0:\n",
    "            KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN = \"finder_cmp_object_image_dropdown\"\n",
    "            finder_cmp_object_image_dropdown = wid.Dropdown(\n",
    "                options=object_images_selected_filenames,\n",
    "                value=memoize.get(\n",
    "                    KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN,\n",
    "                    default=object_images_selected_filenames[0],\n",
    "                    possible_values=object_images_selected_filenames,\n",
    "                ),\n",
    "                description=\"Object image\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            finder_cmp_output = wid.Output()\n",
    "            finder_cmp_output_workaround = wid.VBox([])\n",
    "\n",
    "            # Temporary capturing is bugged in vscode\n",
    "            # @finder_cmp_output.capture(\n",
    "            #    clear_output=True, wait=False\n",
    "            # )\n",
    "            def on_finder_cmp_change(change=None):\n",
    "                memoize.set(\n",
    "                    KEY_FINDER_CMP_OBJECT_IMAGE_DROPDOWN,\n",
    "                    finder_cmp_object_image_dropdown.value,\n",
    "                )\n",
    "\n",
    "                selected_object_image_index = object_images_selected_filenames.index(\n",
    "                    finder_cmp_object_image_dropdown.value\n",
    "                )\n",
    "\n",
    "                selected_object_image_color = object_images_selected[\n",
    "                    selected_object_image_index\n",
    "                ].image_color\n",
    "\n",
    "                selected_object_keypoints = (\n",
    "                    object_recognition_result.detected_objects_keypoints[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                )\n",
    "                selected_scene_keypoints = (\n",
    "                    object_recognition_result.detected_scenes_keypoints[0]\n",
    "                )\n",
    "                selected_matches = object_recognition_result.object_scene_matches[\n",
    "                    selected_object_image_index\n",
    "                ][0]\n",
    "\n",
    "                with LogTimer(\"Displaying sift result\"):\n",
    "                    annotated_image = draw_matches(\n",
    "                        image_1_i=selected_object_image_color,\n",
    "                        keypoints_1=selected_object_keypoints,\n",
    "                        image_2_i=scene_image_selected.image_color,\n",
    "                        keypoints_2=selected_scene_keypoints,\n",
    "                        matches=selected_matches,\n",
    "                    )\n",
    "                    ipy_image = to_ipy_image(\n",
    "                        annotated_image,\n",
    "                        longest_side=image_size * 3,\n",
    "                        upscale=True,\n",
    "                    )\n",
    "                    finder_cmp_output_workaround.children = [ipy_image]\n",
    "                    # sadly bugged on vscode display(ipy_image)\n",
    "\n",
    "            finder_cmp_object_image_dropdown.observe(\n",
    "                on_finder_cmp_change, names=\"value\"\n",
    "            )\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        finder_cmp_object_image_dropdown,\n",
    "                        finder_cmp_output_workaround,\n",
    "                        finder_cmp_output,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_finder_cmp_change()\n",
    "\n",
    "        # RUN RANSAC\n",
    "        KEY_RANSAC_CONFIDENCE_SLIDER = \"ransac_confidence_slider\"\n",
    "        ransac_confidence_slider = wid.FloatSlider(\n",
    "            value=memoize.get(KEY_RANSAC_CONFIDENCE_SLIDER, default=0.85),\n",
    "            min=0.1,\n",
    "            max=0.99,\n",
    "            step=0.01,\n",
    "            continuous_update=False,\n",
    "            orientation=\"horizontal\",\n",
    "            readout=True,\n",
    "            readout_format=\".2f\",\n",
    "            description=\"RANSAC confidence\",\n",
    "            **widgets_styling_slider,\n",
    "        )\n",
    "        KEY_RANSAC_INLIER_THRESHOLD_SLIDER = \"ransac_inlier_threshold_slider\"\n",
    "        ransac_inlier_threshold_slider = wid.FloatSlider(\n",
    "            value=memoize.get(KEY_RANSAC_INLIER_THRESHOLD_SLIDER, default=5.0),\n",
    "            min=0.1,\n",
    "            max=10.0,\n",
    "            step=0.1,\n",
    "            continuous_update=False,\n",
    "            orientation=\"horizontal\",\n",
    "            readout=True,\n",
    "            readout_format=\".1f\",\n",
    "            description=\"RANSAC inlier threshold\",\n",
    "            **widgets_styling_slider,\n",
    "        )\n",
    "        ransac_default_button = wid.Button(\n",
    "            description=\"Default RANSAC\",\n",
    "            **widgets_styling,\n",
    "        )\n",
    "        ransac_output = wid.Output()\n",
    "\n",
    "        @ransac_output.capture(clear_output=True, wait=False)\n",
    "        def on_ransac_change(change=None):\n",
    "            memoize.set(KEY_RANSAC_CONFIDENCE_SLIDER, ransac_confidence_slider.value)\n",
    "            memoize.set(\n",
    "                KEY_RANSAC_INLIER_THRESHOLD_SLIDER, ransac_inlier_threshold_slider.value\n",
    "            )\n",
    "\n",
    "            selected_scene_keypoints = (\n",
    "                object_recognition_result.detected_scenes_keypoints[0]\n",
    "            )\n",
    "            selected_objects_keypoints = [\n",
    "                object_recognition_result.detected_objects_keypoints[i]\n",
    "                for i, _ in enumerate(object_images_selected)\n",
    "            ]\n",
    "\n",
    "            selected_objects_matches = [\n",
    "                object_recognition_result.object_scene_matches[i][0]\n",
    "                for i, _ in enumerate(object_images_selected)\n",
    "            ]\n",
    "\n",
    "            with LogTimer(\"Running find homography\"):\n",
    "                homography_results = []\n",
    "                for selected_object_image_index in range(\n",
    "                    len(object_images_selected_indices)\n",
    "                ):\n",
    "                    selected_object_name = object_images_selected_filenames[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "\n",
    "                    selected_object_keypoints = selected_objects_keypoints[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                    selected_matches = selected_objects_matches[\n",
    "                        selected_object_image_index\n",
    "                    ]\n",
    "                    # get the target (scene) and source (object) points from the matches\n",
    "                    target_points = np.array(\n",
    "                        [\n",
    "                            selected_scene_keypoints[match.trainIdx].pt\n",
    "                            for match in selected_matches\n",
    "                        ],\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "                    source_points = np.array(\n",
    "                        [\n",
    "                            selected_object_keypoints[match.queryIdx].pt\n",
    "                            for match in selected_matches\n",
    "                        ],\n",
    "                        dtype=np.float32,\n",
    "                    )\n",
    "\n",
    "                    with LogTimer(\n",
    "                        f\"Calculating homography for object {selected_object_name}\"\n",
    "                    ):\n",
    "                        homography_result = (\n",
    "                            points_of_interest_impl.find_homography_ransac(\n",
    "                                source_points,\n",
    "                                target_points,\n",
    "                                ransac_confidence_slider.value,\n",
    "                                ransac_inlier_threshold_slider.value,\n",
    "                            )\n",
    "                        )\n",
    "                        display(\n",
    "                            f\"Used {homography_result.num_iterations} iterations to find the homography for object {selected_object_name}\"\n",
    "                        )\n",
    "                    homography_results.append(homography_result)\n",
    "\n",
    "            # Display inliers\n",
    "            KEY_SHOW_INLIERS_CHECKBOX = \"show_inliers_checkbox\"\n",
    "            show_inliers_checkbox = wid.Checkbox(\n",
    "                value=memoize.get(KEY_SHOW_INLIERS_CHECKBOX, default=True),\n",
    "                description=\"Show inliers\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN = (\n",
    "                \"show_inliers_object_image_dropdown\"\n",
    "            )\n",
    "            show_inliers_object_image_dropdown = wid.Dropdown(\n",
    "                options=object_images_selected_filenames,\n",
    "                value=memoize.get(\n",
    "                    KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN,\n",
    "                    default=object_images_selected_filenames[0],\n",
    "                    possible_values=object_images_selected_filenames,\n",
    "                ),\n",
    "                description=\"Object image\",\n",
    "                **widgets_styling,\n",
    "            )\n",
    "            show_inlier_output = wid.Output()\n",
    "            show_inlier_output_workaround = wid.VBox([])\n",
    "\n",
    "            # Temporary capturing is bugged in vscode\n",
    "            # @show_inlier_output.capture(\n",
    "            #    clear_output=True, wait=False\n",
    "            # )\n",
    "            def on_show_inliers_change(change=None):\n",
    "                memoize.set(KEY_SHOW_INLIERS_CHECKBOX, show_inliers_checkbox.value)\n",
    "                memoize.set(\n",
    "                    KEY_SHOW_INLIERS_OBJECT_IMAGE_DROPDOWN,\n",
    "                    show_inliers_object_image_dropdown.value,\n",
    "                )\n",
    "\n",
    "                if show_inliers_checkbox.value:\n",
    "                    show_inlier_output_workaround.children = [\n",
    "                        show_inliers_object_image_dropdown\n",
    "                    ]\n",
    "\n",
    "                    selected_object_image_index = (\n",
    "                        object_images_selected_filenames.index(\n",
    "                            show_inliers_object_image_dropdown.value\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # get the mask boolean array of inliers\n",
    "                    inliers = homography_results[\n",
    "                        selected_object_image_index\n",
    "                    ].debug_inliers\n",
    "\n",
    "                    debug_chosen_source_points = homography_results[\n",
    "                        selected_object_image_index\n",
    "                    ].debug_chosen_source_points\n",
    "\n",
    "                    with LogTimer(\"Drawing inliers\"):\n",
    "                        draw_matches_params = {\"matchesMask\": inliers.astype(int)}\n",
    "                        annotated_image = draw_matches(\n",
    "                            image_1_i=object_images_selected[\n",
    "                                selected_object_image_index\n",
    "                            ].image_color,\n",
    "                            keypoints_1=selected_objects_keypoints[\n",
    "                                selected_object_image_index\n",
    "                            ],\n",
    "                            image_2_i=scene_image_selected.image_color,\n",
    "                            keypoints_2=selected_scene_keypoints,\n",
    "                            matches=selected_objects_matches[\n",
    "                                selected_object_image_index\n",
    "                            ],\n",
    "                            params=draw_matches_params,\n",
    "                        )\n",
    "                        if debug_chosen_source_points is not None:\n",
    "                            for source_point in debug_chosen_source_points:\n",
    "                                cv2.circle(\n",
    "                                    annotated_image,\n",
    "                                    tuple(np.round(source_point).astype(int)),\n",
    "                                    5,\n",
    "                                    (255, 255, 255),\n",
    "                                    -1,\n",
    "                                )\n",
    "                        ipy_image = to_ipy_image(\n",
    "                            annotated_image,\n",
    "                            longest_side=image_size * 3,\n",
    "                            upscale=True,\n",
    "                        )\n",
    "                        # display(ipy_image)\n",
    "                        show_inlier_output_workaround.children = [\n",
    "                            *show_inlier_output_workaround.children,\n",
    "                            ipy_image,\n",
    "                        ]\n",
    "                else:\n",
    "                    show_inlier_output_workaround.children = []\n",
    "\n",
    "            show_inliers_checkbox.observe(on_show_inliers_change, names=\"value\")\n",
    "            show_inliers_object_image_dropdown.observe(\n",
    "                on_show_inliers_change, names=\"value\"\n",
    "            )\n",
    "\n",
    "            display(\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        show_inliers_checkbox,\n",
    "                        show_inlier_output_workaround,\n",
    "                        show_inlier_output,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            on_show_inliers_change()\n",
    "\n",
    "            # Display homography results\n",
    "            annotated_scene_image = scene_image_selected.image_color.copy()\n",
    "            annotated_scene_image_overlay = scene_image_selected.image_color.copy()\n",
    "            for i, homography_result in enumerate(homography_results):\n",
    "                if homography_result.homography is None:\n",
    "                    continue\n",
    "\n",
    "                draw_projected_object(\n",
    "                    annotated_scene_image,\n",
    "                    object_images_selected[i].image_color,\n",
    "                    homography_result.homography,\n",
    "                    draw_object=False,\n",
    "                    fill_color=None,\n",
    "                    outline_color=object_colors[i],\n",
    "                )\n",
    "                draw_projected_object(\n",
    "                    annotated_scene_image_overlay,\n",
    "                    object_images_selected[i].image_color,\n",
    "                    homography_result.homography,\n",
    "                    draw_object=True,\n",
    "                    fill_color=None,\n",
    "                    outline_color=object_colors[i],\n",
    "                )\n",
    "            display(\n",
    "                to_ipy_image(\n",
    "                    annotated_scene_image, longest_side=image_size * 3, upscale=True\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                to_ipy_image(\n",
    "                    annotated_scene_image_overlay,\n",
    "                    longest_side=image_size * 3,\n",
    "                    upscale=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        ransac_confidence_slider.observe(on_ransac_change, names=\"value\")\n",
    "        ransac_inlier_threshold_slider.observe(on_ransac_change, names=\"value\")\n",
    "\n",
    "        def default_ransac(change=None):\n",
    "            memoize.delete_keys(\n",
    "                [\n",
    "                    KEY_RANSAC_CONFIDENCE_SLIDER,\n",
    "                    KEY_RANSAC_INLIER_THRESHOLD_SLIDER,\n",
    "                ]\n",
    "            )\n",
    "            on_finder_image_selection_change()\n",
    "\n",
    "        ransac_default_button.on_click(default_ransac)\n",
    "\n",
    "        display(\n",
    "            wid.VBox(\n",
    "                [\n",
    "                    ransac_confidence_slider,\n",
    "                    ransac_inlier_threshold_slider,\n",
    "                    ransac_default_button,\n",
    "                    ransac_output,\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        on_ransac_change()\n",
    "\n",
    "    finder_object_image_select.set_on_selection_change(on_finder_image_selection_change)\n",
    "    finder_scene_image_select.set_on_selection_change(on_finder_image_selection_change)\n",
    "\n",
    "    display(\n",
    "        wid.VBox(\n",
    "            [\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HTML(\"<h2>Scene images</h2>\"),\n",
    "                        finder_scene_image_select.get_view(),\n",
    "                    ]\n",
    "                ),\n",
    "                wid.VBox(\n",
    "                    [\n",
    "                        wid.HTML(\"<h2>Object images</h2>\"),\n",
    "                        finder_object_image_select.get_view(),\n",
    "                    ]\n",
    "                ),\n",
    "                finder_image_selection_output,\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    on_finder_image_selection_change()\n",
    "\n",
    "\n",
    "finder_image_set_dropdown.observe(on_finder_menu_change, names=\"value\")\n",
    "finder_points_of_interest_impl_dropdown.observe(on_finder_menu_change, names=\"value\")\n",
    "finder_reload_impl_button.on_click(on_finder_menu_change)\n",
    "\n",
    "display(\n",
    "    wid.VBox(\n",
    "        [\n",
    "            wid.HBox(\n",
    "                [\n",
    "                    finder_image_set_dropdown,\n",
    "                    finder_points_of_interest_impl_dropdown,\n",
    "                    finder_reload_impl_button,\n",
    "                ]\n",
    "            ),\n",
    "            finder_output,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "on_finder_menu_change()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "stitching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
